{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T20:06:19.678727Z",
     "start_time": "2021-01-24T20:06:19.049892Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import time, datetime\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device(gpu)를 정해서 사용해야함. multi-gpu를 사용할 수도 있지만, 각 연구원별로 1개로 할당되어있기 때문에, single gpu가 default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:16.330518Z",
     "start_time": "2021-01-22T08:02:10.202053Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 22 17:02:15 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 27%   29C    P0    52W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   30C    P0    58W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1F:00.0 Off |                  N/A |\n",
      "| 26%   29C    P0    62W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:20:00.0 Off |                  N/A |\n",
      "| 27%   32C    P0    64W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:21:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8    25W / 250W |    199MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:22:00.0 Off |                  N/A |\n",
      "| 28%   26C    P0    56W / 250W |      0MiB / 11019MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:23:00.0 Off |                  N/A |\n",
      "| 29%   29C    P0    55W / 250W |      0MiB / 11019MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:24:00.0 Off |                  N/A |\n",
      "| 19%   28C    P0     1W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    4     22045      C   /usr/bin/python3                             189MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:21.930099Z",
     "start_time": "2021-01-22T08:02:16.335295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: GeForce RTX 2080 Ti (cuda:3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_idx = 3\n",
    "\n",
    "if torch.cuda.is_available() and type(gpu_idx) == int:\n",
    "    device = torch.device(\"cuda:{}\".format(gpu_idx))\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(\"Device: {} ({})\\n\".format(torch.cuda.get_device_name(current_device), device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Device: CPU\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:22.186333Z",
     "start_time": "2021-01-22T08:02:21.933827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 22 17:02:22 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 27%   29C    P0    51W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   30C    P0    58W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1F:00.0 Off |                  N/A |\n",
      "| 27%   29C    P0    62W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:20:00.0 Off |                  N/A |\n",
      "| 27%   32C    P0    64W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:21:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8    26W / 250W |    199MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:22:00.0 Off |                  N/A |\n",
      "| 28%   27C    P0    56W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:23:00.0 Off |                  N/A |\n",
      "| 29%   29C    P0    55W / 250W |     10MiB / 11019MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:24:00.0 Off |                  N/A |\n",
      "| 25%   29C    P0    43W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    4     22045      C   /usr/bin/python3                             189MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pkl로 저장된 data_config를 가져와서 훈련 목적에 따라 데이터를 load\n",
    "\n",
    "파일이름을 batch로 받아서 batch단위에서 이미지를 load해서 device를 입혀야 최대한 neural network 훈련에 gpu를 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:22.225289Z",
     "start_time": "2021-01-22T08:02:22.190823Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "from itertools import product\n",
    "\n",
    "def Image_norm(img, mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]):\n",
    "    \"\"\"\n",
    "    img: np.array (h, w, ch) or (n, h, w, ch) ~ [0, 255] integer\n",
    "    mean and std vaules were used for normalizing input data to ImageNet models in torch \n",
    "    \"\"\"\n",
    "    return (img/255-mean)/std\n",
    "\n",
    "def reshape4torch(img, norm = False):\n",
    "    \"\"\"\n",
    "    (sample #, height, width, channel) -> (sample #, channel, height, width)\n",
    "    \"\"\"\n",
    "    if norm == True:\n",
    "        img = Image_norm(img)\n",
    "        \n",
    "    if len(img.shape) == 4:\n",
    "        img = np.transpose(img, (0, 3, 1, 2))\n",
    "        return img\n",
    "    elif len(img.shape) == 3:\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        return np.expand_dims(img, axis=0)\n",
    "\n",
    "def load_image_from_path(path_list, normalization = False, extract_name = False):\n",
    "    data = []\n",
    "    for i in path_list:\n",
    "        temp = cv2.imread(i)\n",
    "\n",
    "        data.append(temp)\n",
    "    if extract_name != False:\n",
    "        name = []\n",
    "        for i in path_list:\n",
    "            name.append(os.path.basename(i))\n",
    "        return reshape4torch(np.asarray(data), norm = normalization), np.asarray(name)\n",
    "    else:\n",
    "        return reshape4torch(np.asarray(data), norm = normalization)\n",
    "    \n",
    "def extract_aug_suffix(frb_switch = [1, 1, 1], sv_switch = True, mode = 'load'):\n",
    "    \"\"\"\n",
    "    frb_switch = [1, 1, 1], [0, 0 ,1], [1, 1, 0].... \n",
    "    that means [flip, rotate, blur_sharp]\n",
    "    \"\"\"\n",
    "    phase0 = ['_c']\n",
    "    phase1 = {1: ['-', 'f'], 0: ['-']}\n",
    "    phase2 = {1: ['-', 'r1', 'r2', 'r3'], 0: ['-']}\n",
    "    phase3 = {1: ['-', 'ab', 'mb', 'eh'], 0: ['-']}\n",
    "    phase4 = ['s_-30_v_30', 's_-30_v_-30', 's_30_v_-30', 's_30_v_30']\n",
    "\n",
    "    if mode == 'load':\n",
    "        phase_a_items = [phase1[frb_switch[0]], phase2[frb_switch[1]], phase3[frb_switch[2]]]\n",
    "    elif mode == 'preprocessing':\n",
    "        phase_a_items = [phase0, phase1[frb_switch[0]], phase2[frb_switch[1]], phase3[frb_switch[2]]]\n",
    "\n",
    "    phase_a = []\n",
    "    for i in list(product(*phase_a_items)):\n",
    "        phase_a.append('_'.join(i))\n",
    "\n",
    "    if not sv_switch == False:\n",
    "        phase_b = []\n",
    "        for i in list(product(*[phase_a, phase4])):\n",
    "            phase_b.append('_'.join(i))\n",
    "        return list(np.hstack([phase_a, phase_b]))\n",
    "    else:\n",
    "        return phase_a \n",
    "\n",
    "def train_data_load(data_config, aug_frb = [0, 0, 0], aug_sv = False):\n",
    "    \"\"\"\n",
    "    data_config: ~~~.pkl\n",
    "    \"\"\"\n",
    "    root = '/mnt/disk2/data/private_data/SMhospital/capsule/1 preprocessed'\n",
    "\n",
    "    data_dir = root + '/database'\n",
    "\n",
    "    with open(root + '/{}'.format(data_config), \"rb\") as f:\n",
    "        data_config = pickle.load(f)\n",
    "\n",
    "    train_aug_files, valid_files = data_config['train_aug_files'], data_config['valid_files']\n",
    "    \n",
    "#     train_aug_files = remove_annotation_mark(train_aug_files)\n",
    "#     valid_files = remove_annotation_mark(valid_files)\n",
    "    \n",
    "    valid_Xs = []\n",
    "    for i, valid_file in enumerate(valid_files):\n",
    "        valid_path = [os.path.join(data_dir, f) for f in valid_file]\n",
    "        valid_Xs.append(load_image_from_path(valid_path))\n",
    "\n",
    "    target_aug = extract_aug_suffix(aug_frb, aug_sv, mode = 'load')\n",
    "\n",
    "    train_aug_paths = []\n",
    "    for train_aug_file in train_aug_files:\n",
    "        train_aug_paths.append([os.path.join(data_dir, f) for f in train_aug_file \n",
    "                                if (f.split('c_')[-1])[:-4] in target_aug])\n",
    "        \n",
    "    print('{:<7}| {:<30}| {:<25}| {:<15}'.format('class', 'total augmented training set', 'target training set (x{})'.format(len(target_aug)), 'validation set'))\n",
    "    for i in range(len(train_aug_files)):\n",
    "        print('{:<7}| {:<30}| {:<25}| {:<15}'.format(i, len(train_aug_files[i]), len(train_aug_paths[i]), len(valid_Xs[i])))\n",
    "        \n",
    "    print()\n",
    "\n",
    "#     print('total augmented training set:', len(train_aug_files[0]), ',', len(train_aug_files[1]))\n",
    "#     print('target augmented training set:', len(train_aug_paths[0]), ',', len(train_aug_paths[1]))\n",
    "#     print('validation set:', len(valid_files[0]), ',', len(valid_files[1]))\n",
    "    \n",
    "    return train_aug_paths, valid_Xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "증강법을 선택하여 training set에 쓰일 파일 경로와 validation set에 쓰일 이미지를 불러올 수 있음\n",
    "\n",
    "- validation set에 쓰이는 데이터는 증강법이 적용이 안되어 데이터 수가 적어 이미지로 불러온 상태로 작업해도 무방하나, training set의 경우, 증강법에 따라 그 수가 커지면 memory에 영향이 가기때문에 파일경로로 가지고 있다가 batch를 불러올 때, 이미지를 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:32.500075Z",
     "start_time": "2021-01-22T08:02:22.229087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class  | total augmented training set  | target training set (x1) | validation set \n",
      "0      | 1094720                       | 6842                     | 1710           \n",
      "1      | 400480                        | 2503                     | 626            \n",
      "\n"
     ]
    }
   ],
   "source": [
    " train_aug_paths, valid_Xs = train_data_load('data_config_np-hd_frb_sv.pkl', aug_frb = [0, 0, 0], aug_sv = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:37.334573Z",
     "start_time": "2021-01-22T08:02:32.506154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2336, 3, 512, 512), torch.Size([2336]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths, n_cls = train_aug_paths, len(train_aug_paths)\n",
    "class_size = []\n",
    "valid_Ys = []\n",
    "classifier_file = None\n",
    "\n",
    "def gen_label(data, cls):\n",
    "#     label = cls*np.ones([data.shape[0]])\n",
    "    label = cls*np.ones([len(data)])\n",
    "    return label\n",
    "\n",
    "for i, train_path, valid_x in zip(range(n_cls), train_paths, valid_Xs):\n",
    "                     \n",
    "    valid_y = gen_label(valid_x, i)                                                                \n",
    "    valid_Ys.append(valid_y)\n",
    "    class_size.append(len(train_path))   \n",
    "                                \n",
    "valid_X = np.concatenate(valid_Xs)\n",
    "valid_Y = torch.tensor(np.concatenate(valid_Ys), device = device).long()\n",
    "\n",
    "valid_X.shape, valid_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:37.340795Z",
     "start_time": "2021-01-22T08:02:37.336842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6842, 2503]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid_Y를 device에 할당시키면서 늘어나는 memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:37.721876Z",
     "start_time": "2021-01-22T08:02:37.342611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 22 17:02:37 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8    13W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8     8W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1F:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8    21W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:20:00.0 Off |                  N/A |\n",
      "| 27%   33C    P2    63W / 250W |    869MiB / 11019MiB |      6%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:21:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8    26W / 250W |    199MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:22:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8     8W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:23:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8    17W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:24:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8     1W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    3      5520      C   /home/project/pytorch/bin/python             859MiB |\n",
      "|    4     22045      C   /usr/bin/python3                             189MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_v1: VGGNet과 유사하지만, SBCE 이미지에 쓰이는 색상이 적고 구분하는 클래스가 적어 훨씬 더 shallow한 network구조로 baseline으로 잡고 있음\n",
    "\n",
    "Transfer learning: 다른 ImageNet에서 훈련된 network들이 heavy해서 3, 512, 512의 이미지 (ImageNet 이미지의 4배 scale)를 훈련시키려면 single gpu 하나로 가능한 훈련배치가 급격히 줄어듬  \n",
    "\n",
    "발전된 network layer와 module 등을 network 구조를 customizing하여 성능을 높일 수는 있으나, 연구적인 novelty는 크게 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:37.757811Z",
     "start_time": "2021-01-22T08:02:37.726206Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN_v1(nn.Module):\n",
    "    def __init__(self, n_ch, n_cls):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1_1 = nn.Conv2d(n_ch, 16, 3, 1, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(16, 16, 3, 1, padding=1)\n",
    "        self.maxp1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(16, 16, 3, 1, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(16, 16, 3, 1, padding=1)\n",
    "        self.maxp2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(16, 16, 3, 1, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(16, 16, 3, 1, padding=1)\n",
    "        self.maxp3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(16, 32, 3, 1, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(32, 32, 3, 1, padding=1)\n",
    "        self.maxp4 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(32, 32, 3, 1, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(32, 32, 3, 1, padding=1)\n",
    "        self.maxp5 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv6_1 = nn.Conv2d(32, 32, 3, 1, padding=1)\n",
    "        self.conv6_2 = nn.Conv2d(32, 32, 3, 1, padding=1)\n",
    "        self.maxp6 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv7_1 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
    "        self.conv7_2 = nn.Conv2d(64, 64, 3, 1, padding=1)\n",
    "        self.maxp7 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.dense1 = nn.Linear(4*4*64, 100)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.dense2 = nn.Linear(100, 50)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.dense3 = nn.Linear(50, n_cls)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxp1(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxp2(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = self.maxp3(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = self.maxp4(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = self.maxp5(x)\n",
    "        x = F.relu(self.conv6_1(x))\n",
    "        x = F.relu(self.conv6_2(x))\n",
    "        x = self.maxp6(x)\n",
    "        x = F.relu(self.conv7_1(x))\n",
    "        x = F.relu(self.conv7_2(x))\n",
    "        x = self.maxp7(x)\n",
    "        # flatten\n",
    "        x = x.view(-1, 4*4*64)\n",
    "        feature = F.relu(self.dense1(x))\n",
    "        x = self.dropout1(feature)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = F.softmax(x, dim = -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary를 통해 input size에 따라 하나의 input에 대한 network 훈련에 드는 총 memory를 볼 수 있음\n",
    "\n",
    "101.39 MB\n",
    "\n",
    "11019 MiB = 11554.258944 MB \n",
    "\n",
    "이론상, 약 100개의 batch training이 최대임을 알 수 있음 (batch training 외에 gpu memory에 데이터가 많이 할당되어있으면 훈련에 쓰는 gpu가 적어짐)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:37.833279Z",
     "start_time": "2021-01-22T08:02:37.760294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 512, 512]             448\n",
      "            Conv2d-2         [-1, 16, 512, 512]           2,320\n",
      "         MaxPool2d-3         [-1, 16, 256, 256]               0\n",
      "            Conv2d-4         [-1, 16, 256, 256]           2,320\n",
      "            Conv2d-5         [-1, 16, 256, 256]           2,320\n",
      "         MaxPool2d-6         [-1, 16, 128, 128]               0\n",
      "            Conv2d-7         [-1, 16, 128, 128]           2,320\n",
      "            Conv2d-8         [-1, 16, 128, 128]           2,320\n",
      "         MaxPool2d-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 32, 64, 64]           4,640\n",
      "           Conv2d-11           [-1, 32, 64, 64]           9,248\n",
      "        MaxPool2d-12           [-1, 32, 32, 32]               0\n",
      "           Conv2d-13           [-1, 32, 32, 32]           9,248\n",
      "           Conv2d-14           [-1, 32, 32, 32]           9,248\n",
      "        MaxPool2d-15           [-1, 32, 16, 16]               0\n",
      "           Conv2d-16           [-1, 32, 16, 16]           9,248\n",
      "           Conv2d-17           [-1, 32, 16, 16]           9,248\n",
      "        MaxPool2d-18             [-1, 32, 8, 8]               0\n",
      "           Conv2d-19             [-1, 64, 8, 8]          18,496\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,928\n",
      "        MaxPool2d-21             [-1, 64, 4, 4]               0\n",
      "           Linear-22                  [-1, 100]         102,500\n",
      "          Dropout-23                  [-1, 100]               0\n",
      "           Linear-24                   [-1, 50]           5,050\n",
      "          Dropout-25                   [-1, 50]               0\n",
      "           Linear-26                    [-1, 2]             102\n",
      "           CNN_v1-27                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 226,004\n",
      "Trainable params: 226,004\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 97.53\n",
      "Params size (MB): 0.86\n",
      "Estimated Total Size (MB): 101.39\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(226004), tensor(226004))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr  = 0.0001\n",
    "\n",
    "input_shape = (3, 512, 512)\n",
    "n_ch, input_h, input_w = input_shape\n",
    "        \n",
    "# if network == 'CNN_v1':\n",
    "#     from ce_model.cnns import CNN_v1\n",
    "network = CNN_v1(n_ch, n_cls)\n",
    "\n",
    "model = network\n",
    "# model = model.cuda()\n",
    "model = model.to(device)\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     cudnn.benchmark = True\n",
    "#         model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "# if summary_show == True:\n",
    "summary(model, (n_ch, input_h, input_w), device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T07:54:01.033660Z",
     "start_time": "2021-01-21T07:54:01.024566Z"
    }
   },
   "source": [
    "network를 device에 할당시키면서 늘어나는 memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:38.237656Z",
     "start_time": "2021-01-22T08:02:37.836021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 22 17:02:38 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8    13W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8     9W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1F:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8    21W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:20:00.0 Off |                  N/A |\n",
      "| 27%   33C    P2    63W / 250W |   1085MiB / 11019MiB |      6%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:21:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8    26W / 250W |    199MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:22:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8     8W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:23:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8    17W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:24:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8     1W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    3      5520      C   /home/project/pytorch/bin/python            1075MiB |\n",
      "|    4     22045      C   /usr/bin/python3                             189MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일한 network (CNN_v1)이면서 이미 훈련된 모델을 쓰고자 한다면 아래 코드로 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:38.249416Z",
     "start_time": "2021-01-22T08:02:38.241862Z"
    }
   },
   "outputs": [],
   "source": [
    "classifider_file = None\n",
    "\n",
    "if classifier_file is not None:\n",
    "# load the weights into generator\n",
    "    print(\"loading classifier_weights from:\", classifier_file, '\\n')\n",
    "#             self.model.load_state_dict(torch.load(classifier_file))\n",
    "    model.load_state_dict(torch.load(classifier_file, map_location=lambda storage, loc: storage.cuda(gpu_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Training\n",
    "- 'equal'은 batch training 단계에서 각 class마다 동일한 갯수의 데이터를 sub-sample하여 batch를 만드는 것\n",
    "- 비교를 위해서 binary classification에 한하여 oversample, undersample이 가능하도록 했지만, 기본적으로 'eqaul'을 사용함\n",
    "- 이는 황윤섭 학위논문에 class-equal batch sampling으로 소개되어 oversample, undersample과 비교하였음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch training을 위한 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:38.274924Z",
     "start_time": "2021-01-22T08:02:38.253128Z"
    }
   },
   "outputs": [],
   "source": [
    "norm = None \n",
    "\n",
    "def load_rand_batch(path, label = None, cls = None, batch_size = 50, mode = 'eqaul', norm = False):\n",
    "    idx = np.random.choice(len(path), batch_size)\n",
    "    if type(path) == list:\n",
    "        path = np.asarray(path)\n",
    "    batch_dir = path[idx]\n",
    "    batch_x = []\n",
    "    for i in batch_dir:\n",
    "        img = cv2.imread(i) # BGR Channel\n",
    "        batch_x.append(img)\n",
    "    if mode == 'equal':\n",
    "        batch_label = gen_label(batch_x, cls)\n",
    "        return reshape4torch(np.asarray(batch_x), norm = norm), batch_label\n",
    "    elif mode == 'mixed':\n",
    "        return reshape4torch(np.asarray(batch_x), norm = norm), label[idx]\n",
    "\n",
    "def rand_shuffle(x1, x2):\n",
    "    \"\"\"\n",
    "    random shuffle of two paired data -> x, y = shuffle(x, y)\n",
    "    but, available of one data -> x = shuffle(x, None)\n",
    "    \"\"\"\n",
    "    idx = np.arange(len(x1))\n",
    "    np.random.shuffle(idx)\n",
    "    if type(x1) == type(x2):\n",
    "        return x1[idx], x2[idx] \n",
    "    else:\n",
    "        return x1[idx]\n",
    "\n",
    "def torch_batch_load(train_paths, batch_size = 100, shuffle = False, mode = 'equal'):\n",
    "    x, y = [], []\n",
    "\n",
    "    if mode == 'equal':\n",
    "        for i, X_i in enumerate(train_paths):\n",
    "            x_i, y_i = load_rand_batch(path = X_i, cls = i, \n",
    "                                       batch_size = batch_size, mode = 'equal', norm = norm)\n",
    "            x.append(x_i), y.append(y_i)\n",
    "        x, y = np.concatenate(x), np.concatenate(y)\n",
    "\n",
    "\n",
    "    elif mode == 'mixed':\n",
    "        Y = []\n",
    "        for i, X_i in enumerate(train_paths):\n",
    "            Y_i = gen_label(X_i, i)\n",
    "            Y.append(Y_i)\n",
    "        X = np.concatenate(train_paths)\n",
    "        Y = np.concatenate(Y)\n",
    "        x, y = load_rand_batch(path = X, label = Y, \n",
    "                               batch_size = batch_size, mode = 'mixed', norm = norm)\n",
    "\n",
    "    if shuffle != False:\n",
    "        x, y = rand_shuffle(x, y)\n",
    "    x, y = torch.tensor(x, device = device).float(), torch.tensor(y, device = device).long()\n",
    "#         x, y = torch.tensor(x, device = 'cpu').float(), torch.tensor(y, device = 'cpu').long()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oversample, undersample을 위한 data sampling 함수 (binary classification 한정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:38.286672Z",
     "start_time": "2021-01-22T08:02:38.277779Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_sampling(train_paths, mode):\n",
    "    if mode == 'undersample':\n",
    "        train_paths_ = train_paths.copy()\n",
    "        n_min = np.min([len(train_paths_[0]), len(train_paths_[1])])\n",
    "        target_cls = np.argmax([len(train_paths_[0]), len(train_paths_[1])])\n",
    "        target_path = np.asarray(train_paths_[target_cls])\n",
    "        undersampled_paths = list(target_path[sorted(np.random.choice(len(target_path), n_min, replace=False))])\n",
    "        train_paths_[target_cls] = undersampled_paths\n",
    "\n",
    "    elif mode == 'oversample':\n",
    "        train_paths_ = train_paths.copy()\n",
    "        n_max = np.max([len(train_paths_[0]), len(train_paths_[1])])\n",
    "        target_cls = np.argmin([len(train_paths_[0]), len(train_paths_[1])])\n",
    "        target_path = np.asarray(train_paths_[target_cls])\n",
    "        n_diff = int(n_max-len(target_path))\n",
    "        if len(target_path) >= n_diff:\n",
    "            oversampled_paths = list(target_path[sorted(np.random.choice(len(target_path), n_diff, replace=False))])\n",
    "        elif len(target_path) < n_diff:\n",
    "            oversampled_paths = list(target_path[sorted(np.random.choice(len(target_path), n_diff, replace=True))])\n",
    "        train_paths_[target_cls] += oversampled_paths\n",
    "\n",
    "    return train_paths_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 중 overfitting을 방지하기 위한 validation 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:38.296352Z",
     "start_time": "2021-01-22T08:02:38.289285Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_idxs(dataset, batch_size = 32, shuffle = False):\n",
    "\n",
    "    idxs = np.arange(len(dataset))\n",
    "    total_size = len(idxs)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idxs)\n",
    "    start = 0\n",
    "    b_idxs = []\n",
    "    while True:\n",
    "        if total_size > start + batch_size: \n",
    "            b_idxs.append(list(idxs[start:start+batch_size]))  \n",
    "            start += batch_size\n",
    "        elif total_size <= start + batch_size: \n",
    "            b_idxs.append(list(idxs[start:]))\n",
    "            break \n",
    "    return b_idxs\n",
    "\n",
    "def validation(X, Y, batch_size = 32):\n",
    "    b_idxs = batch_idxs(X, batch_size)\n",
    "    output = []\n",
    "    for b_idx in b_idxs:\n",
    "        x = torch.tensor(X[b_idx, :, :, :], device = device).float() \n",
    "#             x = X[batch, :, :, :] \n",
    "        o = model(x)\n",
    "        output.append(o)\n",
    "    output = torch.cat(output)\n",
    "    loss = criterion(output, Y)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    return loss, pred  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련의 경과를 보고, 훈련시간을 기록하기 위한 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:38.382986Z",
     "start_time": "2021-01-22T08:02:38.299114Z"
    }
   },
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, prefix = '', suffix = '', decimals = 1, barLength = 100):\n",
    "    formatStr = \"{0:.\" + str(decimals) + \"f}\"\n",
    "    percent = formatStr.format(100 * (iteration / float(total)))\n",
    "    filledLength = int(round(barLength * iteration / float(total)))\n",
    "    bar = '#' * filledLength + '-' * (barLength - filledLength)\n",
    "    sys.stdout.write('\\r{} |{} | {}{} {}'.format(prefix, bar, percent, '%', suffix)),\n",
    "    if iteration == total:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def plot_history(model_name, save_dir = 'training_history'):\n",
    "        \n",
    "    fig = plt.figure(figsize = (20, 8))\n",
    "\n",
    "    # x_axis = range(1, 10*len(accr_hist)+1, 10)\n",
    "#         x_axis = np.arange(10, 10*len(accr_hist)+1, 10)\n",
    "    x_axis = np.arange(1, epoch_i + 1)\n",
    "\n",
    "#         print(x_axis, accr_hist, loss_hist, val_accr_hist, val_loss_hist)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x_axis, accr_hist, 'b-', label = 'Training Accuracy')\n",
    "    plt.plot(x_axis, val_accr_hist, 'r-', label = 'Validation Accuracy')\n",
    "    plt.xlabel('Epoch', fontsize = 15)\n",
    "    plt.ylabel('Accuracy', fontsize = 15)\n",
    "    plt.legend(fontsize = 10)\n",
    "    plt.grid(True)\n",
    "#         plt.grid('on')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x_axis, loss_hist, 'b-', label = 'Training Loss')\n",
    "    plt.plot(x_axis, val_loss_hist, 'r-', label = 'Validation Loss')\n",
    "    plt.xlabel('Epoch', fontsize = 15)\n",
    "    plt.ylabel('Loss', fontsize = 15)\n",
    "    # plt.yticks(np.arange(0, 0.25, step=0.025))\n",
    "    plt.legend(fontsize = 12)\n",
    "#         plt.grid('on')\n",
    "    plt.grid(True)\n",
    "#         plt.show()\n",
    "\n",
    "    save_path = './training_history'\n",
    "    os.makedirs(save_path, exist_ok = True)\n",
    "#         model_name = '_'.join(model_full_name.split('_')[0:3])\n",
    "\n",
    "    hyper_params = '{}_{}'.format(lr, n_batch)\n",
    "    model_name = '{}_{}'.format(model_name, hyper_params)\n",
    "\n",
    "#         print(model_name)\n",
    "\n",
    "    fig.savefig(save_path + '/{}_training_plot.png'.format(model_name), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    np.save(save_path + '/{}_training_log'.format(model_name), [loss_hist, accr_hist, val_loss_hist, val_accr_hist])\n",
    "    \n",
    "def sec_to_m_s_ms(sec):\n",
    "    \"\"\"\n",
    "    sec: time.time() - start_time\n",
    "    output: ex) 00:47.421\n",
    "    \"\"\"\n",
    "    min_sec = time.strftime(\"%M:%S\", time.gmtime(sec))\n",
    "    ms = '{:03d}'.format(int((sec - int(sec))*1000))   \n",
    "    return '.'.join([min_sec, ms])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampling mode와 batch mode에 따른 1 epoch당 iteration 수 계산\n",
    "\n",
    "equal에 경우, n_batch는 각 class마다의 batch 사이즈를 의미함 <br>\n",
    "즉, 32개의 mini batch를 class마다 가져와서 64개의 batch를 input으로 훈련하게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T08:02:38.400595Z",
     "start_time": "2021-01-22T08:02:38.386323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_mode = None\n",
    "batch_mode = 'equal'\n",
    "n_batch = 32\n",
    "\n",
    "if sampling_mode == 'oversample':\n",
    "    if batch_mode == 'equal':\n",
    "        max_iter = np.max(class_size) // n_batch + 1\n",
    "    elif batch_mode == 'mixed':\n",
    "        max_iter = np.max(class_size) // int(n_batch/n_cls) + 1\n",
    "elif sampling_mode == 'undersample':\n",
    "    if batch_mode == 'equal':\n",
    "        max_iter = np.min(class_size) // n_batch + 1\n",
    "    elif batch_mode == 'mixed':\n",
    "        max_iter = np.min(class_size) // int(n_batch/n_cls) + 1\n",
    "elif sampling_mode == None:\n",
    "    if batch_mode == 'equal':\n",
    "        max_iter = np.max(class_size) // n_batch + 1\n",
    "    elif batch_mode == 'mixed':\n",
    "        max_iter = np.sum(class_size) // n_batch + 1\n",
    "        \n",
    "max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training history\n",
    "- Epoch가 끝날때마다 accuracy와 loss의 history를 plot하여 저장해서 해당 폴더에 들어가서 훈련 경과를 볼 수 있음 \n",
    "\n",
    "Training progress verbose\n",
    "- 1: Epoch마다 iteration 경과가 표시되고, training loss & accuracy 및 validation loss & accuracy가 표시됨\n",
    "- 2: Epoch마다 %로  진행경과만 나타남\n",
    "- 3: 진행경과와 epoch마다 걸리는 시간이 나타남 (tqdm)\n",
    "\n",
    "Model Saving\n",
    "- model_name은 저장되는 모델 파일명의 prefix가 되며 data_config의 이름 형식과 유사하게 작성하는 것을 권장함\n",
    "- 본인이 저장한 모델을 개발 목적에 따라 한 눈에 알아보고 추후에 혼동되는 것을 방지하기 위함 \n",
    "- validation loss가 가장 작은 값을 가질 때마다 모델을 저장하며 파일이름에 성능이 들어가 한 눈에 성능을 추정할 수 있도록 함\n",
    "\n",
    "learning scheduler나 early stopping을 사용할 수 있으나, 권장하지는 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T09:08:04.143055Z",
     "start_time": "2021-01-22T08:02:38.403518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 214 for 1 epoch\n",
      "\n",
      "Epoch 001 |###################################################################### | 100.0% \n",
      "train_loss: 0.67213, train_accr: 0.580 | val_loss: 0.68873, val_accr: 0.708 | 01:18.098 elapsed\n",
      "Epoch 002 |###################################################################### | 100.0% \n",
      "train_loss: 0.58013, train_accr: 0.731 | val_loss: 0.60095, val_accr: 0.711 | 01:17.763 elapsed\n",
      "Epoch 003 |###################################################################### | 100.0% \n",
      "train_loss: 0.54944, train_accr: 0.757 | val_loss: 0.50977, val_accr: 0.797 | 01:17.927 elapsed\n",
      "Epoch 004 |###################################################################### | 100.0% \n",
      "train_loss: 0.51629, train_accr: 0.790 | val_loss: 0.49729, val_accr: 0.807 | 01:17.719 elapsed\n",
      "Epoch 005 |###################################################################### | 100.0% \n",
      "train_loss: 0.48338, train_accr: 0.824 | val_loss: 0.45197, val_accr: 0.852 | 01:18.320 elapsed\n",
      "Epoch 006 |###################################################################### | 100.0% \n",
      "train_loss: 0.47588, train_accr: 0.832 | val_loss: 0.50426, val_accr: 0.782 | 01:18.131 elapsed\n",
      "Epoch 007 |###################################################################### | 100.0% \n",
      "train_loss: 0.46967, train_accr: 0.840 | val_loss: 0.44660, val_accr: 0.852 | 01:18.265 elapsed\n",
      "Epoch 008 |###################################################################### | 100.0% \n",
      "train_loss: 0.45265, train_accr: 0.856 | val_loss: 0.43201, val_accr: 0.876 | 01:18.359 elapsed\n",
      "Epoch 009 |###################################################################### | 100.0% \n",
      "train_loss: 0.45354, train_accr: 0.854 | val_loss: 0.44541, val_accr: 0.854 | 01:18.369 elapsed\n",
      "Epoch 010 |###################################################################### | 100.0% \n",
      "train_loss: 0.44656, train_accr: 0.861 | val_loss: 0.42442, val_accr: 0.882 | 01:18.388 elapsed\n",
      "Epoch 011 |###################################################################### | 100.0% \n",
      "train_loss: 0.43641, train_accr: 0.871 | val_loss: 0.44974, val_accr: 0.854 | 01:18.172 elapsed\n",
      "Epoch 012 |###################################################################### | 100.0% \n",
      "train_loss: 0.42973, train_accr: 0.879 | val_loss: 0.42057, val_accr: 0.884 | 01:18.283 elapsed\n",
      "Epoch 013 |###################################################################### | 100.0% \n",
      "train_loss: 0.43492, train_accr: 0.875 | val_loss: 0.44145, val_accr: 0.863 | 01:18.068 elapsed\n",
      "Epoch 014 |###################################################################### | 100.0% \n",
      "train_loss: 0.42887, train_accr: 0.879 | val_loss: 0.41889, val_accr: 0.891 | 01:17.709 elapsed\n",
      "Epoch 015 |###################################################################### | 100.0% \n",
      "train_loss: 0.42795, train_accr: 0.881 | val_loss: 0.42638, val_accr: 0.882 | 01:17.921 elapsed\n",
      "Epoch 016 |###################################################################### | 100.0% \n",
      "train_loss: 0.42562, train_accr: 0.883 | val_loss: 0.41695, val_accr: 0.893 | 01:18.197 elapsed\n",
      "Epoch 017 |###################################################################### | 100.0% \n",
      "train_loss: 0.41804, train_accr: 0.892 | val_loss: 0.45485, val_accr: 0.848 | 01:17.878 elapsed\n",
      "Epoch 018 |###################################################################### | 100.0% \n",
      "train_loss: 0.41557, train_accr: 0.895 | val_loss: 0.41417, val_accr: 0.896 | 01:17.828 elapsed\n",
      "Epoch 019 |###################################################################### | 100.0% \n",
      "train_loss: 0.41571, train_accr: 0.895 | val_loss: 0.48454, val_accr: 0.820 | 01:18.044 elapsed\n",
      "Epoch 020 |###################################################################### | 100.0% \n",
      "train_loss: 0.41275, train_accr: 0.898 | val_loss: 0.41978, val_accr: 0.890 | 01:17.815 elapsed\n",
      "Epoch 021 |###################################################################### | 100.0% \n",
      "train_loss: 0.41192, train_accr: 0.899 | val_loss: 0.40638, val_accr: 0.902 | 01:18.032 elapsed\n",
      "Epoch 022 |###################################################################### | 100.0% \n",
      "train_loss: 0.40868, train_accr: 0.902 | val_loss: 0.44905, val_accr: 0.855 | 01:17.913 elapsed\n",
      "Epoch 023 |###################################################################### | 100.0% \n",
      "train_loss: 0.40560, train_accr: 0.904 | val_loss: 0.39339, val_accr: 0.915 | 01:18.178 elapsed\n",
      "Epoch 024 |###################################################################### | 100.0% \n",
      "train_loss: 0.40182, train_accr: 0.909 | val_loss: 0.39471, val_accr: 0.911 | 01:17.889 elapsed\n",
      "Epoch 025 |###################################################################### | 100.0% \n",
      "train_loss: 0.39716, train_accr: 0.913 | val_loss: 0.40802, val_accr: 0.899 | 01:18.106 elapsed\n",
      "Epoch 026 |###################################################################### | 100.0% \n",
      "train_loss: 0.39389, train_accr: 0.917 | val_loss: 0.38593, val_accr: 0.925 | 01:18.376 elapsed\n",
      "Epoch 027 |###################################################################### | 100.0% \n",
      "train_loss: 0.39432, train_accr: 0.917 | val_loss: 0.39680, val_accr: 0.913 | 01:18.370 elapsed\n",
      "Epoch 028 |###################################################################### | 100.0% \n",
      "train_loss: 0.39219, train_accr: 0.919 | val_loss: 0.38309, val_accr: 0.926 | 01:18.191 elapsed\n",
      "Epoch 029 |###################################################################### | 100.0% \n",
      "train_loss: 0.39186, train_accr: 0.920 | val_loss: 0.39003, val_accr: 0.918 | 01:18.606 elapsed\n",
      "Epoch 030 |###################################################################### | 100.0% \n",
      "train_loss: 0.38991, train_accr: 0.922 | val_loss: 0.40100, val_accr: 0.908 | 01:18.594 elapsed\n",
      "Epoch 031 |###################################################################### | 100.0% \n",
      "train_loss: 0.39125, train_accr: 0.919 | val_loss: 0.38404, val_accr: 0.926 | 01:17.173 elapsed\n",
      "Epoch 032 |###################################################################### | 100.0% \n",
      "train_loss: 0.38545, train_accr: 0.926 | val_loss: 0.37664, val_accr: 0.935 | 01:18.157 elapsed\n",
      "Epoch 033 |###################################################################### | 100.0% \n",
      "train_loss: 0.38520, train_accr: 0.926 | val_loss: 0.38253, val_accr: 0.930 | 01:18.278 elapsed\n",
      "Epoch 034 |###################################################################### | 100.0% \n",
      "train_loss: 0.38335, train_accr: 0.927 | val_loss: 0.39521, val_accr: 0.913 | 01:18.264 elapsed\n",
      "Epoch 035 |###################################################################### | 100.0% \n",
      "train_loss: 0.38980, train_accr: 0.922 | val_loss: 0.38672, val_accr: 0.923 | 01:17.903 elapsed\n",
      "Epoch 036 |###################################################################### | 100.0% \n",
      "train_loss: 0.38182, train_accr: 0.930 | val_loss: 0.38583, val_accr: 0.923 | 01:17.775 elapsed\n",
      "Epoch 037 |###################################################################### | 100.0% \n",
      "train_loss: 0.38340, train_accr: 0.928 | val_loss: 0.38912, val_accr: 0.919 | 01:17.815 elapsed\n",
      "Epoch 038 |###################################################################### | 100.0% \n",
      "train_loss: 0.38319, train_accr: 0.928 | val_loss: 0.41201, val_accr: 0.897 | 01:18.260 elapsed\n",
      "Epoch 039 |###################################################################### | 100.0% \n",
      "train_loss: 0.37886, train_accr: 0.932 | val_loss: 0.37989, val_accr: 0.931 | 01:18.236 elapsed\n",
      "Epoch 040 |###################################################################### | 100.0% \n",
      "train_loss: 0.38047, train_accr: 0.931 | val_loss: 0.38830, val_accr: 0.921 | 01:17.985 elapsed\n",
      "Epoch 041 |###################################################################### | 100.0% \n",
      "train_loss: 0.37974, train_accr: 0.932 | val_loss: 0.37575, val_accr: 0.935 | 01:17.866 elapsed\n",
      "Epoch 042 |###################################################################### | 100.0% \n",
      "train_loss: 0.37624, train_accr: 0.935 | val_loss: 0.37431, val_accr: 0.937 | 01:18.046 elapsed\n",
      "Epoch 043 |###################################################################### | 100.0% \n",
      "train_loss: 0.37227, train_accr: 0.940 | val_loss: 0.37919, val_accr: 0.932 | 01:18.078 elapsed\n",
      "Epoch 044 |###################################################################### | 100.0% \n",
      "train_loss: 0.37658, train_accr: 0.935 | val_loss: 0.38336, val_accr: 0.929 | 01:18.216 elapsed\n",
      "Epoch 045 |###################################################################### | 100.0% \n",
      "train_loss: 0.37657, train_accr: 0.935 | val_loss: 0.37579, val_accr: 0.938 | 01:18.204 elapsed\n",
      "Epoch 046 |###################################################################### | 100.0% \n",
      "train_loss: 0.37047, train_accr: 0.941 | val_loss: 0.37834, val_accr: 0.933 | 01:18.224 elapsed\n",
      "Epoch 047 |###################################################################### | 100.0% \n",
      "train_loss: 0.37309, train_accr: 0.939 | val_loss: 0.39431, val_accr: 0.912 | 01:18.545 elapsed\n",
      "Epoch 048 |###################################################################### | 100.0% \n",
      "train_loss: 0.37241, train_accr: 0.940 | val_loss: 0.38809, val_accr: 0.925 | 01:18.399 elapsed\n",
      "Epoch 049 |###################################################################### | 100.0% \n",
      "train_loss: 0.37834, train_accr: 0.934 | val_loss: 0.40956, val_accr: 0.899 | 01:17.733 elapsed\n",
      "Epoch 050 |###################################################################### | 100.0% \n",
      "train_loss: 0.36720, train_accr: 0.945 | val_loss: 0.37538, val_accr: 0.936 | 01:18.405 elapsed\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 50\n",
    "verbose = 1\n",
    "model_name = 'np-hd_---_--'\n",
    "n_patient = None\n",
    "\n",
    "if verbose == 3:\n",
    "    pbar = tqdm(total=n_epoch, unit='epoch', bar_format='{l_bar}{bar:40}{r_bar}')\n",
    "\n",
    "loss_hist, accr_hist = [], []\n",
    "val_loss_hist, val_accr_hist = [], []\n",
    "\n",
    "iter_i = 0\n",
    "epoch_i = 0\n",
    "patient_i = 0\n",
    "\n",
    "save_path = './model'\n",
    "os.makedirs(save_path, exist_ok = True)  \n",
    "\n",
    "print('Iteration {} for 1 epoch\\n'.format(max_iter))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "\n",
    "    if iter_i == 0:\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        if sampling_mode:\n",
    "            sampled_train_paths = data_sampling(train_paths, mode = sampling_mode)\n",
    "\n",
    "    if sampling_mode:\n",
    "        train_x, train_y = torch_batch_load(sampled_train_paths, n_batch, mode = batch_mode, shuffle = True)\n",
    "    else:\n",
    "        train_x, train_y = torch_batch_load(train_paths, n_batch, mode = batch_mode, shuffle = True)\n",
    "\n",
    "    output = model(train_x)\n",
    "    loss = criterion(output, train_y)\n",
    "\n",
    "    _, pred = torch.max(output, 1)\n",
    "\n",
    "    train_loss += loss.item()\n",
    "    train_correct += torch.mean((pred == train_y.detach()).float()).item()\n",
    "\n",
    "#             train_loss.append(loss.item())\n",
    "#             train_correct.append(torch.mean((pred == train_y.detach()).float()))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "\n",
    "    iter_i += 1\n",
    "\n",
    "    if verbose == 1:\n",
    "        progress_bar(iter_i, max_iter, prefix = 'Epoch {:03d}'.format(epoch_i+1), \n",
    "                      suffix = '', barLength = 70)\n",
    "\n",
    "    if iter_i % max_iter == 0:   \n",
    "\n",
    "        epoch_i += 1\n",
    "        patient_i += 1\n",
    "\n",
    "        loss_hist.append(train_loss / iter_i)\n",
    "        accr_hist.append(train_correct / iter_i)\n",
    "\n",
    "#                 model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            valid_loss, valid_pred = validation(valid_X, valid_Y, batch_size = 8)\n",
    "\n",
    "            val_loss_hist.append(valid_loss.item())\n",
    "            val_accr_hist.append((torch.mean((valid_pred == valid_Y.detach()).float()).item()))\n",
    "\n",
    "\n",
    "        if (val_accr_hist[-1] == np.max(val_accr_hist)): \n",
    "\n",
    "            patient_i = 0\n",
    "\n",
    "            now = datetime.datetime.now()\n",
    "            nowDatetime = now.strftime('%y%m%d%H%M')\n",
    "            hyper_params = '{}_{}'.format(lr, n_batch)\n",
    "            tr_spec = 't_accr_{:.4f}_t_loss_{:.6f}'.format(accr_hist[-1], loss_hist[-1])\n",
    "            vl_spec = 'v_accr_{:.4f}_v_loss_{:.6f}'.format(val_accr_hist[-1], val_loss_hist[-1])\n",
    "            model_full_name = '{}_{}_{}_{:03d}_{}_{}.pt'.format(model_name, \n",
    "                                                                hyper_params, nowDatetime, epoch_i, tr_spec, vl_spec)\n",
    "            torch.save(model.state_dict(), save_path + '/' + model_full_name)\n",
    "\n",
    "        if verbose == 1:\n",
    "            train_prt = 'train_loss: {:.5f}, train_accr: {:.3f}'.format(loss_hist[-1], accr_hist[-1])\n",
    "            val_prt = 'val_loss: {:.5f}, val_accr: {:.3f}'.format(val_loss_hist[-1], val_accr_hist[-1])\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(\"{} | {} | {} elapsed\".format(train_prt, val_prt, sec_to_m_s_ms(elapsed_time)))\n",
    "\n",
    "        if verbose == 2:\n",
    "            progress_bar(epoch_i, n_epoch, \n",
    "                          prefix = 'Training Epoch', suffix = '({}/{})'.format(epoch_i, n_epoch), \n",
    "                          barLength = 70)\n",
    "        if verbose == 3:\n",
    "            pbar.update(1)\n",
    "\n",
    "        if patient_i == n_patient:\n",
    "            break\n",
    "\n",
    "        plot_history(model_name) \n",
    "        iter_i = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "    if epoch_i == n_epoch:\n",
    "#             if epoch_i == 2:\n",
    "#                 print(loss_hist, accr_hist)\n",
    "#                 print(val_loss_hist, val_accr_hist)\n",
    "        break\n",
    "\n",
    "if verbose == 3:        \n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection\n",
    "- 저장된 모델들 중에 training loss와 validation loss의 합이 가장 작은 model 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T20:06:55.453716Z",
     "start_time": "2021-01-24T20:06:55.444848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['np-hd_---_--_0.0001_32_2101221706_003_t_accr_0.7570_t_loss_0.549435_v_accr_0.7967_v_loss_0.509768.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221707_004_t_accr_0.7899_t_loss_0.516286_v_accr_0.8065_v_loss_0.497294.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221709_005_t_accr_0.8243_t_loss_0.483379_v_accr_0.8519_v_loss_0.451969.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221711_007_t_accr_0.8396_t_loss_0.469670_v_accr_0.8519_v_loss_0.446602.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221713_008_t_accr_0.8559_t_loss_0.452650_v_accr_0.8759_v_loss_0.432012.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221715_010_t_accr_0.8611_t_loss_0.446560_v_accr_0.8818_v_loss_0.424417.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221718_012_t_accr_0.8792_t_loss_0.429733_v_accr_0.8840_v_loss_0.420574.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221720_014_t_accr_0.8792_t_loss_0.428873_v_accr_0.8908_v_loss_0.418895.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221723_016_t_accr_0.8834_t_loss_0.425618_v_accr_0.8934_v_loss_0.416949.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221726_018_t_accr_0.8949_t_loss_0.415567_v_accr_0.8960_v_loss_0.414165.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221730_021_t_accr_0.8992_t_loss_0.411917_v_accr_0.9020_v_loss_0.406383.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221732_023_t_accr_0.9041_t_loss_0.405600_v_accr_0.9152_v_loss_0.393394.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221736_026_t_accr_0.9171_t_loss_0.393891_v_accr_0.9247_v_loss_0.385934.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221739_028_t_accr_0.9192_t_loss_0.392192_v_accr_0.9264_v_loss_0.383086.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221743_031_t_accr_0.9191_t_loss_0.391250_v_accr_0.9264_v_loss_0.384036.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221744_032_t_accr_0.9260_t_loss_0.385446_v_accr_0.9354_v_loss_0.376643.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221757_042_t_accr_0.9350_t_loss_0.376242_v_accr_0.9366_v_loss_0.374310.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221801_045_t_accr_0.9349_t_loss_0.376567_v_accr_0.9379_v_loss_0.375792.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221703_001_t_accr_0.5797_t_loss_0.672134_v_accr_0.7085_v_loss_0.688729.pt',\n",
       "       'np-hd_---_--_0.0001_32_2101221705_002_t_accr_0.7313_t_loss_0.580130_v_accr_0.7115_v_loss_0.600955.pt'],\n",
       "      dtype='<U100')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = './model'\n",
    "\n",
    "model_list = np.array([i for i in os.listdir(model_path) if model_name + '_' in i])\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T20:07:00.651904Z",
     "start_time": "2021-01-24T20:07:00.645281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_model = len(model_list)\n",
    "n_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T20:07:18.862254Z",
     "start_time": "2021-01-24T20:07:18.847168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.059203, 1.01358 , 0.935348, 0.916272, 0.884662, 0.870977,\n",
       "       0.850307, 0.847768, 0.842567, 0.829732, 0.8183  , 0.798994,\n",
       "       0.779825, 0.775278, 0.775286, 0.762089, 0.750552, 0.752359,\n",
       "       1.360863, 1.181085])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_loss, v_loss = np.zeros([n_model]), np.zeros([n_model])\n",
    "\n",
    "for i, file in zip(range(n_model), model_list):\n",
    "    t_loss[i] = file.split('t_loss')[-1].split('_')[1]\n",
    "    v_loss[i] = file.split('v_loss')[-1].split('_')[1][:-3]\n",
    "    \n",
    "t_loss + v_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T20:08:11.664430Z",
     "start_time": "2021-01-24T20:08:11.655356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.750552])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx = np.where((t_loss+v_loss) == np.min(t_loss+v_loss))[0]\n",
    "(t_loss + v_loss)[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T20:08:22.568575Z",
     "start_time": "2021-01-24T20:08:22.553124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: np-hd_---_--_0.0001_32_2101221757_042_t_accr_0.9350_t_loss_0.376242_v_accr_0.9366_v_loss_0.374310.pt\n"
     ]
    }
   ],
   "source": [
    "delete_idx = np.setdiff1d(np.arange(n_model), best_idx)\n",
    "for i in delete_idx:\n",
    "    os.remove(model_path + '/' + model_list[i])\n",
    "print('Best Model:', model_list[int(best_idx)])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
