{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f re-training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T07:54:01.489096Z",
     "start_time": "2020-10-30T07:54:00.897157Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, pickle\n",
    "from itertools import product\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/disk1/yunseob/Pytorch/1_CapsuleEndo/algorithms')\n",
    "from ce_utils.data import train_data_load\n",
    "from ce_model.training import cnn_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T07:54:01.770904Z",
     "start_time": "2020-10-30T07:54:01.491359Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 30 16:54:01 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 27%   23C    P8     1W / 250W |    909MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   23C    P8     4W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:1F:00.0 Off |                  N/A |\n",
      "| 27%   22C    P8    15W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:20:00.0 Off |                  N/A |\n",
      "| 30%   42C    P2    64W / 250W |   1481MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  On   | 00000000:21:00.0 Off |                  N/A |\n",
      "| 27%   22C    P8    20W / 250W |  10627MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  On   | 00000000:22:00.0 Off |                  N/A |\n",
      "| 27%   23C    P8     7W / 250W |  10960MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  On   | 00000000:23:00.0 Off |                  N/A |\n",
      "| 34%   56C    P2   148W / 250W |   6379MiB / 11019MiB |     80%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  On   | 00000000:24:00.0 Off |                  N/A |\n",
      "| 27%   25C    P8     1W / 250W |   1962MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      2855      C   /usr/bin/python3                             899MiB |\n",
      "|    3     39398      C   /home/yunseob/Pytorch/bin/python            1471MiB |\n",
      "|    4     43839      C   /usr/bin/python3                           10615MiB |\n",
      "|    5     37800      C   /usr/bin/python3                             693MiB |\n",
      "|    5     39024      C   /usr/bin/python3                           10257MiB |\n",
      "|    6     18912      C   python3                                     6369MiB |\n",
      "|    7     21738      C   /usr/bin/python3                             189MiB |\n",
      "|    7     29409      C   /home/yunseob/Pytorch/bin/python            1763MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T15:55:00.320110Z",
     "start_time": "2020-10-30T07:54:03.249065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class  | total augmented training set  | target training set (x2) | validation set \n",
      "0      | 1094720                       | 13684                    | 1710           \n",
      "1      | 400480                        | 5006                     | 626            \n",
      "\n",
      "Learning Rate: 0.0001, Batch Size: 16\n",
      "\n",
      "Device: GeForce RTX 2080 Ti \n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 512, 512]             448\n",
      "            Conv2d-2         [-1, 16, 512, 512]           2,320\n",
      "         MaxPool2d-3         [-1, 16, 256, 256]               0\n",
      "            Conv2d-4         [-1, 16, 256, 256]           2,320\n",
      "            Conv2d-5         [-1, 16, 256, 256]           2,320\n",
      "         MaxPool2d-6         [-1, 16, 128, 128]               0\n",
      "            Conv2d-7         [-1, 16, 128, 128]           2,320\n",
      "            Conv2d-8         [-1, 16, 128, 128]           2,320\n",
      "         MaxPool2d-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 32, 64, 64]           4,640\n",
      "           Conv2d-11           [-1, 32, 64, 64]           9,248\n",
      "        MaxPool2d-12           [-1, 32, 32, 32]               0\n",
      "           Conv2d-13           [-1, 32, 32, 32]           9,248\n",
      "           Conv2d-14           [-1, 32, 32, 32]           9,248\n",
      "        MaxPool2d-15           [-1, 32, 16, 16]               0\n",
      "           Conv2d-16           [-1, 32, 16, 16]           9,248\n",
      "           Conv2d-17           [-1, 32, 16, 16]           9,248\n",
      "        MaxPool2d-18             [-1, 32, 8, 8]               0\n",
      "           Conv2d-19             [-1, 64, 8, 8]          18,496\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,928\n",
      "        MaxPool2d-21             [-1, 64, 4, 4]               0\n",
      "           Linear-22                  [-1, 100]         102,500\n",
      "          Dropout-23                  [-1, 100]               0\n",
      "           Linear-24                   [-1, 50]           5,050\n",
      "          Dropout-25                   [-1, 50]               0\n",
      "           Linear-26                    [-1, 2]             102\n",
      "           CNN_v1-27                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 226,004\n",
      "Trainable params: 226,004\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 97.53\n",
      "Params size (MB): 0.86\n",
      "Estimated Total Size (MB): 101.39\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Iteration 856 for 1 epoch\n",
      "\n",
      "Epoch 001 |###################################################################### | 100.0% \n",
      "train_loss: 0.62256, train_accr: 0.646 | val_loss: 0.53816, val_accr: 0.769 | 04:32.599 elapsed\n",
      "Epoch 002 |###################################################################### | 100.0% \n",
      "train_loss: 0.52909, train_accr: 0.777 | val_loss: 0.45508, val_accr: 0.859 | 04:48.105 elapsed\n",
      "Epoch 003 |###################################################################### | 100.0% \n",
      "train_loss: 0.50412, train_accr: 0.802 | val_loss: 0.44279, val_accr: 0.868 | 04:47.842 elapsed\n",
      "Epoch 004 |###################################################################### | 100.0% \n",
      "train_loss: 0.49403, train_accr: 0.813 | val_loss: 0.44294, val_accr: 0.864 | 04:48.788 elapsed\n",
      "Epoch 005 |###################################################################### | 100.0% \n",
      "train_loss: 0.48205, train_accr: 0.826 | val_loss: 0.50472, val_accr: 0.797 | 04:45.560 elapsed\n",
      "Epoch 006 |###################################################################### | 100.0% \n",
      "train_loss: 0.46598, train_accr: 0.842 | val_loss: 0.41836, val_accr: 0.892 | 04:48.748 elapsed\n",
      "Epoch 007 |###################################################################### | 100.0% \n",
      "train_loss: 0.45034, train_accr: 0.858 | val_loss: 0.43265, val_accr: 0.876 | 04:47.792 elapsed\n",
      "Epoch 008 |###################################################################### | 100.0% \n",
      "train_loss: 0.45207, train_accr: 0.856 | val_loss: 0.41311, val_accr: 0.895 | 04:48.823 elapsed\n",
      "Epoch 009 |###################################################################### | 100.0% \n",
      "train_loss: 0.43614, train_accr: 0.873 | val_loss: 0.40409, val_accr: 0.908 | 04:49.944 elapsed\n",
      "Epoch 010 |###################################################################### | 100.0% \n",
      "train_loss: 0.43195, train_accr: 0.877 | val_loss: 0.42036, val_accr: 0.886 | 04:48.617 elapsed\n",
      "Epoch 011 |###################################################################### | 100.0% \n",
      "train_loss: 0.42429, train_accr: 0.885 | val_loss: 0.39338, val_accr: 0.914 | 04:47.975 elapsed\n",
      "Epoch 012 |###################################################################### | 100.0% \n",
      "train_loss: 0.41217, train_accr: 0.898 | val_loss: 0.54728, val_accr: 0.762 | 04:48.553 elapsed\n",
      "Epoch 013 |###################################################################### | 100.0% \n",
      "train_loss: 0.41901, train_accr: 0.890 | val_loss: 0.39566, val_accr: 0.913 | 04:47.798 elapsed\n",
      "Epoch 014 |###################################################################### | 100.0% \n",
      "train_loss: 0.40591, train_accr: 0.904 | val_loss: 0.38569, val_accr: 0.925 | 04:49.772 elapsed\n",
      "Epoch 015 |###################################################################### | 100.0% \n",
      "train_loss: 0.40122, train_accr: 0.909 | val_loss: 0.42082, val_accr: 0.888 | 04:49.609 elapsed\n",
      "Epoch 016 |###################################################################### | 100.0% \n",
      "train_loss: 0.39587, train_accr: 0.914 | val_loss: 0.44640, val_accr: 0.862 | 04:47.791 elapsed\n",
      "Epoch 017 |###################################################################### | 100.0% \n",
      "train_loss: 0.39085, train_accr: 0.919 | val_loss: 0.38088, val_accr: 0.930 | 04:48.312 elapsed\n",
      "Epoch 018 |###################################################################### | 100.0% \n",
      "train_loss: 0.39408, train_accr: 0.917 | val_loss: 0.45256, val_accr: 0.855 | 04:48.095 elapsed\n",
      "Epoch 019 |###################################################################### | 100.0% \n",
      "train_loss: 0.39261, train_accr: 0.918 | val_loss: 0.37507, val_accr: 0.934 | 04:48.265 elapsed\n",
      "Epoch 020 |###################################################################### | 100.0% \n",
      "train_loss: 0.38656, train_accr: 0.924 | val_loss: 0.40526, val_accr: 0.905 | 04:47.494 elapsed\n",
      "Epoch 021 |###################################################################### | 100.0% \n",
      "train_loss: 0.38643, train_accr: 0.924 | val_loss: 0.37372, val_accr: 0.936 | 04:48.347 elapsed\n",
      "Epoch 022 |###################################################################### | 100.0% \n",
      "train_loss: 0.38467, train_accr: 0.926 | val_loss: 0.38876, val_accr: 0.922 | 04:47.873 elapsed\n",
      "Epoch 023 |###################################################################### | 100.0% \n",
      "train_loss: 0.38269, train_accr: 0.929 | val_loss: 0.39893, val_accr: 0.909 | 04:48.469 elapsed\n",
      "Epoch 024 |###################################################################### | 100.0% \n",
      "train_loss: 0.37656, train_accr: 0.935 | val_loss: 0.36530, val_accr: 0.946 | 04:48.257 elapsed\n",
      "Epoch 025 |###################################################################### | 100.0% \n",
      "train_loss: 0.37390, train_accr: 0.937 | val_loss: 0.40927, val_accr: 0.900 | 04:48.392 elapsed\n",
      "Epoch 026 |###################################################################### | 100.0% \n",
      "train_loss: 0.37257, train_accr: 0.938 | val_loss: 0.37451, val_accr: 0.938 | 04:47.755 elapsed\n",
      "Epoch 027 |###################################################################### | 100.0% \n",
      "train_loss: 0.37485, train_accr: 0.936 | val_loss: 0.37138, val_accr: 0.940 | 04:48.221 elapsed\n",
      "Epoch 028 |###################################################################### | 100.0% \n",
      "train_loss: 0.36789, train_accr: 0.944 | val_loss: 0.38709, val_accr: 0.922 | 04:48.831 elapsed\n",
      "Epoch 029 |###################################################################### | 100.0% \n",
      "train_loss: 0.37125, train_accr: 0.940 | val_loss: 0.37293, val_accr: 0.937 | 04:48.505 elapsed\n",
      "Epoch 030 |###################################################################### | 100.0% \n",
      "train_loss: 0.36915, train_accr: 0.942 | val_loss: 0.39529, val_accr: 0.917 | 04:47.514 elapsed\n",
      "Epoch 031 |###################################################################### | 100.0% \n",
      "train_loss: 0.36483, train_accr: 0.947 | val_loss: 0.37691, val_accr: 0.934 | 04:48.405 elapsed\n",
      "Epoch 032 |###################################################################### | 100.0% \n",
      "train_loss: 0.36503, train_accr: 0.946 | val_loss: 0.36902, val_accr: 0.940 | 04:48.445 elapsed\n",
      "Epoch 033 |###################################################################### | 100.0% \n",
      "train_loss: 0.36334, train_accr: 0.948 | val_loss: 0.37400, val_accr: 0.938 | 04:48.373 elapsed\n",
      "Epoch 034 |###################################################################### | 100.0% \n",
      "train_loss: 0.35951, train_accr: 0.953 | val_loss: 0.37965, val_accr: 0.930 | 04:48.001 elapsed\n",
      "Epoch 035 |###################################################################### | 100.0% \n",
      "train_loss: 0.35955, train_accr: 0.953 | val_loss: 0.35931, val_accr: 0.954 | 04:47.735 elapsed\n",
      "Epoch 036 |###################################################################### | 100.0% \n",
      "train_loss: 0.35908, train_accr: 0.953 | val_loss: 0.36769, val_accr: 0.944 | 04:47.798 elapsed\n",
      "Epoch 037 |###################################################################### | 100.0% \n",
      "train_loss: 0.35899, train_accr: 0.953 | val_loss: 0.36006, val_accr: 0.951 | 04:48.002 elapsed\n",
      "Epoch 038 |###################################################################### | 100.0% \n",
      "train_loss: 0.35442, train_accr: 0.958 | val_loss: 0.36082, val_accr: 0.951 | 04:47.400 elapsed\n",
      "Epoch 039 |###################################################################### | 100.0% \n",
      "train_loss: 0.35948, train_accr: 0.953 | val_loss: 0.37628, val_accr: 0.935 | 04:48.455 elapsed\n",
      "Epoch 040 |###################################################################### | 100.0% \n",
      "train_loss: 0.35690, train_accr: 0.955 | val_loss: 0.36198, val_accr: 0.949 | 04:47.990 elapsed\n",
      "Epoch 041 |###################################################################### | 100.0% \n",
      "train_loss: 0.35212, train_accr: 0.960 | val_loss: 0.35715, val_accr: 0.955 | 04:48.151 elapsed\n",
      "Epoch 042 |###################################################################### | 100.0% \n",
      "train_loss: 0.35063, train_accr: 0.962 | val_loss: 0.36164, val_accr: 0.949 | 04:48.404 elapsed\n",
      "Epoch 043 |###################################################################### | 100.0% \n",
      "train_loss: 0.35666, train_accr: 0.955 | val_loss: 0.36203, val_accr: 0.948 | 04:48.401 elapsed\n",
      "Epoch 044 |###################################################################### | 100.0% \n",
      "train_loss: 0.35510, train_accr: 0.957 | val_loss: 0.37125, val_accr: 0.939 | 04:48.123 elapsed\n",
      "Epoch 045 |###################################################################### | 100.0% \n",
      "train_loss: 0.34737, train_accr: 0.965 | val_loss: 0.39965, val_accr: 0.911 | 04:48.779 elapsed\n",
      "Epoch 046 |###################################################################### | 100.0% \n",
      "train_loss: 0.34971, train_accr: 0.962 | val_loss: 0.36580, val_accr: 0.944 | 04:48.185 elapsed\n",
      "Epoch 047 |###################################################################### | 100.0% \n",
      "train_loss: 0.35008, train_accr: 0.962 | val_loss: 0.36889, val_accr: 0.943 | 04:49.436 elapsed\n",
      "Epoch 048 |###################################################################### | 100.0% \n",
      "train_loss: 0.34695, train_accr: 0.966 | val_loss: 0.36441, val_accr: 0.948 | 04:48.240 elapsed\n",
      "Epoch 049 |###################################################################### | 100.0% \n",
      "train_loss: 0.34978, train_accr: 0.962 | val_loss: 0.40135, val_accr: 0.908 | 04:48.358 elapsed\n",
      "Epoch 050 |###################################################################### | 100.0% \n",
      "train_loss: 0.34778, train_accr: 0.964 | val_loss: 0.36013, val_accr: 0.952 | 04:47.299 elapsed\n",
      "Epoch 051 |###################################################################### | 100.0% \n",
      "train_loss: 0.34325, train_accr: 0.969 | val_loss: 0.38613, val_accr: 0.925 | 04:48.032 elapsed\n",
      "Epoch 052 |###################################################################### | 100.0% \n",
      "train_loss: 0.34809, train_accr: 0.964 | val_loss: 0.35501, val_accr: 0.958 | 04:48.066 elapsed\n",
      "Epoch 053 |###################################################################### | 100.0% \n",
      "train_loss: 0.34425, train_accr: 0.968 | val_loss: 0.35938, val_accr: 0.952 | 04:47.824 elapsed\n",
      "Epoch 054 |###################################################################### | 100.0% \n",
      "train_loss: 0.34464, train_accr: 0.968 | val_loss: 0.35946, val_accr: 0.954 | 04:47.999 elapsed\n",
      "Epoch 055 |###################################################################### | 100.0% \n",
      "train_loss: 0.34308, train_accr: 0.969 | val_loss: 0.35875, val_accr: 0.954 | 04:48.120 elapsed\n",
      "Epoch 056 |###################################################################### | 100.0% \n",
      "train_loss: 0.34252, train_accr: 0.970 | val_loss: 0.35492, val_accr: 0.957 | 04:49.168 elapsed\n",
      "Epoch 057 |###################################################################### | 100.0% \n",
      "train_loss: 0.34401, train_accr: 0.968 | val_loss: 0.35401, val_accr: 0.959 | 04:48.915 elapsed\n",
      "Epoch 058 |###################################################################### | 100.0% \n",
      "train_loss: 0.33904, train_accr: 0.974 | val_loss: 0.38174, val_accr: 0.928 | 04:48.211 elapsed\n",
      "Epoch 059 |###################################################################### | 100.0% \n",
      "train_loss: 0.34515, train_accr: 0.968 | val_loss: 0.35680, val_accr: 0.955 | 04:48.352 elapsed\n",
      "Epoch 060 |###################################################################### | 100.0% \n",
      "train_loss: 0.34587, train_accr: 0.967 | val_loss: 0.36154, val_accr: 0.951 | 04:48.425 elapsed\n",
      "Epoch 061 |###################################################################### | 100.0% \n",
      "train_loss: 0.34491, train_accr: 0.968 | val_loss: 0.35644, val_accr: 0.957 | 04:48.004 elapsed\n",
      "Epoch 062 |###################################################################### | 100.0% \n",
      "train_loss: 0.33792, train_accr: 0.974 | val_loss: 0.35865, val_accr: 0.952 | 04:48.070 elapsed\n",
      "Epoch 063 |###################################################################### | 100.0% \n",
      "train_loss: 0.34521, train_accr: 0.967 | val_loss: 0.36155, val_accr: 0.951 | 04:48.214 elapsed\n",
      "Epoch 064 |###################################################################### | 100.0% \n",
      "train_loss: 0.34230, train_accr: 0.970 | val_loss: 0.37477, val_accr: 0.938 | 04:47.736 elapsed\n",
      "Epoch 065 |###################################################################### | 100.0% \n",
      "train_loss: 0.34102, train_accr: 0.971 | val_loss: 0.36534, val_accr: 0.946 | 04:47.905 elapsed\n",
      "Epoch 066 |###################################################################### | 100.0% \n",
      "train_loss: 0.33826, train_accr: 0.974 | val_loss: 0.36544, val_accr: 0.946 | 04:47.459 elapsed\n",
      "Epoch 067 |###################################################################### | 100.0% \n",
      "train_loss: 0.34413, train_accr: 0.969 | val_loss: 0.35546, val_accr: 0.956 | 04:47.840 elapsed\n",
      "Epoch 068 |###################################################################### | 100.0% \n",
      "train_loss: 0.33611, train_accr: 0.976 | val_loss: 0.37328, val_accr: 0.938 | 04:47.312 elapsed\n",
      "Epoch 069 |###################################################################### | 100.0% \n",
      "train_loss: 0.33967, train_accr: 0.973 | val_loss: 0.35735, val_accr: 0.956 | 04:48.080 elapsed\n",
      "Epoch 070 |###################################################################### | 100.0% \n",
      "train_loss: 0.34046, train_accr: 0.972 | val_loss: 0.35940, val_accr: 0.953 | 04:48.565 elapsed\n",
      "Epoch 071 |###################################################################### | 100.0% \n",
      "train_loss: 0.33691, train_accr: 0.976 | val_loss: 0.35434, val_accr: 0.958 | 04:48.267 elapsed\n",
      "Epoch 072 |###################################################################### | 100.0% \n",
      "train_loss: 0.34174, train_accr: 0.971 | val_loss: 0.35760, val_accr: 0.955 | 04:47.681 elapsed\n",
      "Epoch 073 |###################################################################### | 100.0% \n",
      "train_loss: 0.33725, train_accr: 0.976 | val_loss: 0.37042, val_accr: 0.942 | 04:48.263 elapsed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 074 |###################################################################### | 100.0% \n",
      "train_loss: 0.33700, train_accr: 0.976 | val_loss: 0.36294, val_accr: 0.950 | 04:48.544 elapsed\n",
      "Epoch 075 |###################################################################### | 100.0% \n",
      "train_loss: 0.34049, train_accr: 0.972 | val_loss: 0.36727, val_accr: 0.943 | 04:48.168 elapsed\n",
      "Epoch 076 |###################################################################### | 100.0% \n",
      "train_loss: 0.33482, train_accr: 0.978 | val_loss: 0.35992, val_accr: 0.952 | 04:47.971 elapsed\n",
      "Epoch 077 |###################################################################### | 100.0% \n",
      "train_loss: 0.33368, train_accr: 0.979 | val_loss: 0.35496, val_accr: 0.958 | 04:48.111 elapsed\n",
      "Epoch 078 |###################################################################### | 100.0% \n",
      "train_loss: 0.33677, train_accr: 0.976 | val_loss: 0.36073, val_accr: 0.952 | 04:47.656 elapsed\n",
      "Epoch 079 |###################################################################### | 100.0% \n",
      "train_loss: 0.33909, train_accr: 0.974 | val_loss: 0.35758, val_accr: 0.955 | 04:48.579 elapsed\n",
      "Epoch 080 |###################################################################### | 100.0% \n",
      "train_loss: 0.33584, train_accr: 0.977 | val_loss: 0.36468, val_accr: 0.949 | 04:47.422 elapsed\n",
      "Epoch 081 |###################################################################### | 100.0% \n",
      "train_loss: 0.33623, train_accr: 0.977 | val_loss: 0.36038, val_accr: 0.952 | 04:47.965 elapsed\n",
      "Epoch 082 |###################################################################### | 100.0% \n",
      "train_loss: 0.33345, train_accr: 0.979 | val_loss: 0.36236, val_accr: 0.951 | 04:47.920 elapsed\n",
      "Epoch 083 |###################################################################### | 100.0% \n",
      "train_loss: 0.33169, train_accr: 0.981 | val_loss: 0.36888, val_accr: 0.942 | 04:47.891 elapsed\n",
      "Epoch 084 |###################################################################### | 100.0% \n",
      "train_loss: 0.33606, train_accr: 0.977 | val_loss: 0.35694, val_accr: 0.955 | 04:47.526 elapsed\n",
      "Epoch 085 |###################################################################### | 100.0% \n",
      "train_loss: 0.33804, train_accr: 0.975 | val_loss: 0.35816, val_accr: 0.955 | 04:48.069 elapsed\n",
      "Epoch 086 |###################################################################### | 100.0% \n",
      "train_loss: 0.33615, train_accr: 0.977 | val_loss: 0.36580, val_accr: 0.947 | 04:47.282 elapsed\n",
      "Epoch 087 |###################################################################### | 100.0% \n",
      "train_loss: 0.33079, train_accr: 0.982 | val_loss: 0.36075, val_accr: 0.952 | 04:48.023 elapsed\n",
      "Epoch 088 |###################################################################### | 100.0% \n",
      "train_loss: 0.33534, train_accr: 0.978 | val_loss: 0.35481, val_accr: 0.957 | 04:47.950 elapsed\n",
      "Epoch 089 |###################################################################### | 100.0% \n",
      "train_loss: 0.33665, train_accr: 0.976 | val_loss: 0.36230, val_accr: 0.950 | 04:47.817 elapsed\n",
      "Epoch 090 |###################################################################### | 100.0% \n",
      "train_loss: 0.33844, train_accr: 0.974 | val_loss: 0.35962, val_accr: 0.953 | 04:47.458 elapsed\n",
      "Epoch 091 |###################################################################### | 100.0% \n",
      "train_loss: 0.33224, train_accr: 0.980 | val_loss: 0.36457, val_accr: 0.948 | 04:49.234 elapsed\n",
      "Epoch 092 |###################################################################### | 100.0% \n",
      "train_loss: 0.33121, train_accr: 0.982 | val_loss: 0.36649, val_accr: 0.945 | 04:47.245 elapsed\n",
      "Epoch 093 |###################################################################### | 100.0% \n",
      "train_loss: 0.33414, train_accr: 0.979 | val_loss: 0.36984, val_accr: 0.943 | 04:48.772 elapsed\n",
      "Epoch 094 |###################################################################### | 100.0% \n",
      "train_loss: 0.33341, train_accr: 0.980 | val_loss: 0.35740, val_accr: 0.955 | 04:47.639 elapsed\n",
      "Epoch 095 |###################################################################### | 100.0% \n",
      "train_loss: 0.33621, train_accr: 0.976 | val_loss: 0.35986, val_accr: 0.953 | 04:47.655 elapsed\n",
      "Epoch 096 |###################################################################### | 100.0% \n",
      "train_loss: 0.33353, train_accr: 0.979 | val_loss: 0.35769, val_accr: 0.955 | 04:47.111 elapsed\n",
      "Epoch 097 |###################################################################### | 100.0% \n",
      "train_loss: 0.33139, train_accr: 0.982 | val_loss: 0.36515, val_accr: 0.946 | 04:47.925 elapsed\n",
      "Epoch 098 |###################################################################### | 100.0% \n",
      "train_loss: 0.33601, train_accr: 0.977 | val_loss: 0.36125, val_accr: 0.951 | 04:47.564 elapsed\n",
      "Epoch 099 |###################################################################### | 100.0% \n",
      "train_loss: 0.33118, train_accr: 0.982 | val_loss: 0.35662, val_accr: 0.955 | 04:47.149 elapsed\n",
      "Epoch 100 |###################################################################### | 100.0% \n",
      "train_loss: 0.33234, train_accr: 0.981 | val_loss: 0.37028, val_accr: 0.940 | 04:47.347 elapsed\n",
      "Best Model: B_f--_re_0.0001_16_2010302128_057_t_accr_0.9683_t_loss_0.344012_v_accr_0.9589_v_loss_0.354011.pt\n"
     ]
    }
   ],
   "source": [
    "phase_a = [[1, 0, 0]]\n",
    "phase_a_label = ['f--']\n",
    "\n",
    "for frb, name in zip(phase_a, phase_a_label):\n",
    "\n",
    "    train_aug_paths, valid_Xs = train_data_load('data_config_np-hd_frb_sv.pkl', frb, False)\n",
    "\n",
    "    LRs = [0.0001]\n",
    "    BSs = [16]\n",
    "    \n",
    "    Params = list(product(*[LRs, BSs]))\n",
    "\n",
    "    model_spec = 1\n",
    "\n",
    "    for i, (lr, bs) in enumerate(Params):\n",
    "\n",
    "        print('Learning Rate: {}, Batch Size: {}\\n'.format(lr, bs))  \n",
    "\n",
    "        ct = cnn_training(input_shape = [3, 512, 512], lr = lr, n_batch = bs, n_epoch = 100)\n",
    "\n",
    "        ct.run(train_aug_paths, valid_Xs, sampling_mode = None, batch_mode = 'equal', \n",
    "               network = 'CNN_v1', model_spec = model_spec, verbose = 1, \n",
    "               save_path = './model/', model_name = 'B_{}_re'.format(name), gpu_idx = 3,\n",
    "               classifier_file = None)  \n",
    "\n",
    "        if i != 0: model_spec = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T03:49:24.333479Z",
     "start_time": "2020-11-02T01:36:00.005916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class  | total augmented training set  | target training set (x2) | validation set \n",
      "0      | 1094720                       | 13684                    | 1710           \n",
      "1      | 400480                        | 5006                     | 626            \n",
      "\n",
      "Learning Rate: 0.0001, Batch Size: 16\n",
      "\n",
      "Device: GeForce RTX 2080 Ti \n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 512, 512]             448\n",
      "            Conv2d-2         [-1, 16, 512, 512]           2,320\n",
      "         MaxPool2d-3         [-1, 16, 256, 256]               0\n",
      "            Conv2d-4         [-1, 16, 256, 256]           2,320\n",
      "            Conv2d-5         [-1, 16, 256, 256]           2,320\n",
      "         MaxPool2d-6         [-1, 16, 128, 128]               0\n",
      "            Conv2d-7         [-1, 16, 128, 128]           2,320\n",
      "            Conv2d-8         [-1, 16, 128, 128]           2,320\n",
      "         MaxPool2d-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 32, 64, 64]           4,640\n",
      "           Conv2d-11           [-1, 32, 64, 64]           9,248\n",
      "        MaxPool2d-12           [-1, 32, 32, 32]               0\n",
      "           Conv2d-13           [-1, 32, 32, 32]           9,248\n",
      "           Conv2d-14           [-1, 32, 32, 32]           9,248\n",
      "        MaxPool2d-15           [-1, 32, 16, 16]               0\n",
      "           Conv2d-16           [-1, 32, 16, 16]           9,248\n",
      "           Conv2d-17           [-1, 32, 16, 16]           9,248\n",
      "        MaxPool2d-18             [-1, 32, 8, 8]               0\n",
      "           Conv2d-19             [-1, 64, 8, 8]          18,496\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,928\n",
      "        MaxPool2d-21             [-1, 64, 4, 4]               0\n",
      "           Linear-22                  [-1, 100]         102,500\n",
      "          Dropout-23                  [-1, 100]               0\n",
      "           Linear-24                   [-1, 50]           5,050\n",
      "          Dropout-25                   [-1, 50]               0\n",
      "           Linear-26                    [-1, 2]             102\n",
      "           CNN_v1-27                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 226,004\n",
      "Trainable params: 226,004\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 97.53\n",
      "Params size (MB): 0.86\n",
      "Estimated Total Size (MB): 101.39\n",
      "----------------------------------------------------------------\n",
      "\n",
      "loading classifier_weights from: /mnt/disk1/yunseob/Pytorch/1_CapsuleEndo/model_developlment/1_detection_localization/2_data_aug/model/model/B_f--_re_0.0001_16_2010302128_057_t_accr_0.9683_t_loss_0.344012_v_accr_0.9589_v_loss_0.354011.pt \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                        | 0/50 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 856 for 1 epoch\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 50/50 [2:13:12<00:00, 159.86s/epoch]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: B_f--_re_v2_0.0001_16_2011021249_050_t_accr_0.9851_t_loss_0.328059_v_accr_0.9598_v_loss_0.354353.pt\n"
     ]
    }
   ],
   "source": [
    "trained_model = '/mnt/disk1/yunseob/Pytorch/1_CapsuleEndo/model_developlment/1_detection_localization/2_data_aug/model/model/B_f--_re_0.0001_16_2010302128_057_t_accr_0.9683_t_loss_0.344012_v_accr_0.9589_v_loss_0.354011.pt'\n",
    "\n",
    "phase_a = [[1, 0, 0]]\n",
    "phase_a_label = ['f--']\n",
    "\n",
    "for frb, name in zip(phase_a, phase_a_label):\n",
    "\n",
    "    train_aug_paths, valid_Xs = train_data_load('data_config_np-hd_frb_sv.pkl', frb, False)\n",
    "\n",
    "    LRs = [0.0001]\n",
    "    BSs = [16]\n",
    "    \n",
    "    Params = list(product(*[LRs, BSs]))\n",
    "\n",
    "    model_spec = 1\n",
    "\n",
    "    for i, (lr, bs) in enumerate(Params):\n",
    "\n",
    "        print('Learning Rate: {}, Batch Size: {}\\n'.format(lr, bs))  \n",
    "\n",
    "        ct = cnn_training(input_shape = [3, 512, 512], lr = lr, n_batch = bs, n_epoch = 50)\n",
    "\n",
    "        ct.run(train_aug_paths, valid_Xs, sampling_mode = None, batch_mode = 'equal', \n",
    "               network = 'CNN_v1', model_spec = model_spec, verbose = 3, \n",
    "               save_path = './model/', model_name = 'B_{}_re_v2'.format(name), gpu_idx = 3,\n",
    "               classifier_file = trained_model)  \n",
    "\n",
    "        if i != 0: model_spec = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
