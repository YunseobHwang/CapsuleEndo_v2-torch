{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b re-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T07:54:16.743117Z",
     "start_time": "2020-10-30T07:54:16.110553Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, pickle\n",
    "from itertools import product\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/disk1/yunseob/Pytorch/1_CapsuleEndo/algorithms')\n",
    "from ce_utils.data import train_data_load\n",
    "from ce_model.training import cnn_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T07:54:23.966758Z",
     "start_time": "2020-10-30T07:54:23.690184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 30 16:54:23 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 27%   23C    P8     1W / 250W |    909MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   23C    P8     5W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:1F:00.0 Off |                  N/A |\n",
      "| 27%   22C    P8    15W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:20:00.0 Off |                  N/A |\n",
      "| 30%   40C    P2   182W / 250W |   5053MiB / 11019MiB |     71%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  On   | 00000000:21:00.0 Off |                  N/A |\n",
      "| 27%   22C    P8    20W / 250W |  10627MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  On   | 00000000:22:00.0 Off |                  N/A |\n",
      "| 27%   23C    P8     6W / 250W |  10960MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  On   | 00000000:23:00.0 Off |                  N/A |\n",
      "| 34%   57C    P2   210W / 250W |   6379MiB / 11019MiB |     88%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  On   | 00000000:24:00.0 Off |                  N/A |\n",
      "| 27%   25C    P8     1W / 250W |   1962MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      2855      C   /usr/bin/python3                             899MiB |\n",
      "|    3     39525      C   /home/yunseob/Pytorch/bin/python            5043MiB |\n",
      "|    4     43839      C   /usr/bin/python3                           10615MiB |\n",
      "|    5     37800      C   /usr/bin/python3                             693MiB |\n",
      "|    5     39024      C   /usr/bin/python3                           10257MiB |\n",
      "|    6     18912      C   python3                                     6369MiB |\n",
      "|    7     21738      C   /usr/bin/python3                             189MiB |\n",
      "|    7     29409      C   /home/yunseob/Pytorch/bin/python            1763MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T20:33:54.507859Z",
     "start_time": "2020-10-30T07:54:27.359777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class  | total augmented training set  | target training set (x4) | validation set \n",
      "0      | 1094720                       | 27368                    | 1710           \n",
      "1      | 400480                        | 10012                    | 626            \n",
      "\n",
      "Learning Rate: 0.0001, Batch Size: 16\n",
      "\n",
      "Device: GeForce RTX 2080 Ti \n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 512, 512]             448\n",
      "            Conv2d-2         [-1, 16, 512, 512]           2,320\n",
      "         MaxPool2d-3         [-1, 16, 256, 256]               0\n",
      "            Conv2d-4         [-1, 16, 256, 256]           2,320\n",
      "            Conv2d-5         [-1, 16, 256, 256]           2,320\n",
      "         MaxPool2d-6         [-1, 16, 128, 128]               0\n",
      "            Conv2d-7         [-1, 16, 128, 128]           2,320\n",
      "            Conv2d-8         [-1, 16, 128, 128]           2,320\n",
      "         MaxPool2d-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 32, 64, 64]           4,640\n",
      "           Conv2d-11           [-1, 32, 64, 64]           9,248\n",
      "        MaxPool2d-12           [-1, 32, 32, 32]               0\n",
      "           Conv2d-13           [-1, 32, 32, 32]           9,248\n",
      "           Conv2d-14           [-1, 32, 32, 32]           9,248\n",
      "        MaxPool2d-15           [-1, 32, 16, 16]               0\n",
      "           Conv2d-16           [-1, 32, 16, 16]           9,248\n",
      "           Conv2d-17           [-1, 32, 16, 16]           9,248\n",
      "        MaxPool2d-18             [-1, 32, 8, 8]               0\n",
      "           Conv2d-19             [-1, 64, 8, 8]          18,496\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,928\n",
      "        MaxPool2d-21             [-1, 64, 4, 4]               0\n",
      "           Linear-22                  [-1, 100]         102,500\n",
      "          Dropout-23                  [-1, 100]               0\n",
      "           Linear-24                   [-1, 50]           5,050\n",
      "          Dropout-25                   [-1, 50]               0\n",
      "           Linear-26                    [-1, 2]             102\n",
      "           CNN_v1-27                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 226,004\n",
      "Trainable params: 226,004\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 97.53\n",
      "Params size (MB): 0.86\n",
      "Estimated Total Size (MB): 101.39\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Iteration 1711 for 1 epoch\n",
      "\n",
      "Epoch 001 |###################################################################### | 100.0% \n",
      "train_loss: 0.55318, train_accr: 0.741 | val_loss: 0.48437, val_accr: 0.821 | 09:32.583 elapsed\n",
      "Epoch 002 |###################################################################### | 100.0% \n",
      "train_loss: 0.48875, train_accr: 0.818 | val_loss: 0.45006, val_accr: 0.860 | 09:31.016 elapsed\n",
      "Epoch 003 |###################################################################### | 100.0% \n",
      "train_loss: 0.44095, train_accr: 0.868 | val_loss: 0.43205, val_accr: 0.878 | 09:32.999 elapsed\n",
      "Epoch 004 |###################################################################### | 100.0% \n",
      "train_loss: 0.42399, train_accr: 0.885 | val_loss: 0.39556, val_accr: 0.917 | 09:30.827 elapsed\n",
      "Epoch 005 |###################################################################### | 100.0% \n",
      "train_loss: 0.41553, train_accr: 0.894 | val_loss: 0.42371, val_accr: 0.885 | 09:32.799 elapsed\n",
      "Epoch 006 |###################################################################### | 100.0% \n",
      "train_loss: 0.40593, train_accr: 0.905 | val_loss: 0.42340, val_accr: 0.887 | 09:30.556 elapsed\n",
      "Epoch 007 |###################################################################### | 100.0% \n",
      "train_loss: 0.39573, train_accr: 0.915 | val_loss: 0.38583, val_accr: 0.922 | 09:31.668 elapsed\n",
      "Epoch 008 |###################################################################### | 100.0% \n",
      "train_loss: 0.39268, train_accr: 0.918 | val_loss: 0.37862, val_accr: 0.933 | 09:32.588 elapsed\n",
      "Epoch 009 |###################################################################### | 100.0% \n",
      "train_loss: 0.38686, train_accr: 0.924 | val_loss: 0.37916, val_accr: 0.931 | 09:30.940 elapsed\n",
      "Epoch 010 |###################################################################### | 100.0% \n",
      "train_loss: 0.38188, train_accr: 0.929 | val_loss: 0.37893, val_accr: 0.933 | 09:30.230 elapsed\n",
      "Epoch 011 |###################################################################### | 100.0% \n",
      "train_loss: 0.37849, train_accr: 0.933 | val_loss: 0.38838, val_accr: 0.922 | 09:30.717 elapsed\n",
      "Epoch 012 |###################################################################### | 100.0% \n",
      "train_loss: 0.37633, train_accr: 0.935 | val_loss: 0.40934, val_accr: 0.899 | 09:31.555 elapsed\n",
      "Epoch 013 |###################################################################### | 100.0% \n",
      "train_loss: 0.37583, train_accr: 0.936 | val_loss: 0.38889, val_accr: 0.919 | 09:30.145 elapsed\n",
      "Epoch 014 |###################################################################### | 100.0% \n",
      "train_loss: 0.37176, train_accr: 0.940 | val_loss: 0.38240, val_accr: 0.928 | 09:31.598 elapsed\n",
      "Epoch 015 |###################################################################### | 100.0% \n",
      "train_loss: 0.36912, train_accr: 0.943 | val_loss: 0.36964, val_accr: 0.942 | 09:30.168 elapsed\n",
      "Epoch 016 |###################################################################### | 100.0% \n",
      "train_loss: 0.36657, train_accr: 0.945 | val_loss: 0.37334, val_accr: 0.938 | 09:31.386 elapsed\n",
      "Epoch 017 |###################################################################### | 100.0% \n",
      "train_loss: 0.36418, train_accr: 0.948 | val_loss: 0.37365, val_accr: 0.939 | 09:30.516 elapsed\n",
      "Epoch 018 |###################################################################### | 100.0% \n",
      "train_loss: 0.36287, train_accr: 0.950 | val_loss: 0.37740, val_accr: 0.931 | 09:29.865 elapsed\n",
      "Epoch 019 |###################################################################### | 100.0% \n",
      "train_loss: 0.35861, train_accr: 0.954 | val_loss: 0.38888, val_accr: 0.921 | 09:30.215 elapsed\n",
      "Epoch 020 |###################################################################### | 100.0% \n",
      "train_loss: 0.35515, train_accr: 0.957 | val_loss: 0.37369, val_accr: 0.937 | 09:30.299 elapsed\n",
      "Epoch 021 |###################################################################### | 100.0% \n",
      "train_loss: 0.35604, train_accr: 0.956 | val_loss: 0.36734, val_accr: 0.946 | 09:31.250 elapsed\n",
      "Epoch 022 |###################################################################### | 100.0% \n",
      "train_loss: 0.35607, train_accr: 0.956 | val_loss: 0.37575, val_accr: 0.935 | 09:30.818 elapsed\n",
      "Epoch 023 |###################################################################### | 100.0% \n",
      "train_loss: 0.35181, train_accr: 0.961 | val_loss: 0.37494, val_accr: 0.937 | 09:31.627 elapsed\n",
      "Epoch 024 |###################################################################### | 100.0% \n",
      "train_loss: 0.35096, train_accr: 0.962 | val_loss: 0.36485, val_accr: 0.948 | 09:31.549 elapsed\n",
      "Epoch 025 |###################################################################### | 100.0% \n",
      "train_loss: 0.34755, train_accr: 0.965 | val_loss: 0.36606, val_accr: 0.945 | 09:31.505 elapsed\n",
      "Epoch 026 |###################################################################### | 100.0% \n",
      "train_loss: 0.34752, train_accr: 0.965 | val_loss: 0.36887, val_accr: 0.943 | 09:29.929 elapsed\n",
      "Epoch 027 |###################################################################### | 100.0% \n",
      "train_loss: 0.34885, train_accr: 0.964 | val_loss: 0.37338, val_accr: 0.938 | 09:30.730 elapsed\n",
      "Epoch 028 |###################################################################### | 100.0% \n",
      "train_loss: 0.34625, train_accr: 0.967 | val_loss: 0.37852, val_accr: 0.932 | 09:30.346 elapsed\n",
      "Epoch 029 |###################################################################### | 100.0% \n",
      "train_loss: 0.34469, train_accr: 0.968 | val_loss: 0.36961, val_accr: 0.943 | 09:32.586 elapsed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 |###################################################################### | 100.0% \n",
      "train_loss: 0.34114, train_accr: 0.972 | val_loss: 0.36296, val_accr: 0.950 | 09:31.864 elapsed\n",
      "Epoch 031 |###################################################################### | 100.0% \n",
      "train_loss: 0.34239, train_accr: 0.971 | val_loss: 0.37223, val_accr: 0.938 | 09:30.127 elapsed\n",
      "Epoch 032 |###################################################################### | 100.0% \n",
      "train_loss: 0.34036, train_accr: 0.973 | val_loss: 0.36886, val_accr: 0.942 | 09:30.612 elapsed\n",
      "Epoch 033 |###################################################################### | 100.0% \n",
      "train_loss: 0.34236, train_accr: 0.970 | val_loss: 0.36748, val_accr: 0.944 | 09:29.833 elapsed\n",
      "Epoch 034 |###################################################################### | 100.0% \n",
      "train_loss: 0.33972, train_accr: 0.973 | val_loss: 0.37675, val_accr: 0.935 | 09:30.238 elapsed\n",
      "Epoch 035 |###################################################################### | 100.0% \n",
      "train_loss: 0.33965, train_accr: 0.973 | val_loss: 0.37358, val_accr: 0.938 | 09:30.529 elapsed\n",
      "Epoch 036 |###################################################################### | 100.0% \n",
      "train_loss: 0.33752, train_accr: 0.975 | val_loss: 0.36515, val_accr: 0.945 | 09:31.284 elapsed\n",
      "Epoch 037 |###################################################################### | 100.0% \n",
      "train_loss: 0.33827, train_accr: 0.975 | val_loss: 0.36790, val_accr: 0.945 | 09:30.541 elapsed\n",
      "Epoch 038 |###################################################################### | 100.0% \n",
      "train_loss: 0.33709, train_accr: 0.976 | val_loss: 0.36442, val_accr: 0.948 | 09:31.196 elapsed\n",
      "Epoch 039 |###################################################################### | 100.0% \n",
      "train_loss: 0.33634, train_accr: 0.977 | val_loss: 0.36686, val_accr: 0.946 | 09:30.562 elapsed\n",
      "Epoch 040 |###################################################################### | 100.0% \n",
      "train_loss: 0.33632, train_accr: 0.977 | val_loss: 0.36480, val_accr: 0.948 | 09:30.413 elapsed\n",
      "Epoch 041 |###################################################################### | 100.0% \n",
      "train_loss: 0.33531, train_accr: 0.978 | val_loss: 0.36811, val_accr: 0.944 | 09:30.083 elapsed\n",
      "Epoch 042 |###################################################################### | 100.0% \n",
      "train_loss: 0.33356, train_accr: 0.979 | val_loss: 0.36657, val_accr: 0.944 | 09:30.089 elapsed\n",
      "Epoch 043 |###################################################################### | 100.0% \n",
      "train_loss: 0.33243, train_accr: 0.980 | val_loss: 0.36694, val_accr: 0.946 | 09:30.202 elapsed\n",
      "Epoch 044 |###################################################################### | 100.0% \n",
      "train_loss: 0.33221, train_accr: 0.981 | val_loss: 0.36739, val_accr: 0.945 | 09:30.263 elapsed\n",
      "Epoch 045 |###################################################################### | 100.0% \n",
      "train_loss: 0.33168, train_accr: 0.981 | val_loss: 0.37119, val_accr: 0.940 | 09:30.441 elapsed\n",
      "Epoch 046 |###################################################################### | 100.0% \n",
      "train_loss: 0.33267, train_accr: 0.980 | val_loss: 0.36827, val_accr: 0.943 | 09:31.257 elapsed\n",
      "Epoch 047 |###################################################################### | 100.0% \n",
      "train_loss: 0.33073, train_accr: 0.982 | val_loss: 0.36612, val_accr: 0.947 | 09:30.930 elapsed\n",
      "Epoch 048 |###################################################################### | 100.0% \n",
      "train_loss: 0.33233, train_accr: 0.981 | val_loss: 0.36925, val_accr: 0.942 | 09:30.030 elapsed\n",
      "Epoch 049 |###################################################################### | 100.0% \n",
      "train_loss: 0.33105, train_accr: 0.982 | val_loss: 0.37322, val_accr: 0.940 | 09:29.764 elapsed\n",
      "Epoch 050 |###################################################################### | 100.0% \n",
      "train_loss: 0.33171, train_accr: 0.981 | val_loss: 0.37152, val_accr: 0.941 | 09:29.281 elapsed\n",
      "Epoch 051 |###################################################################### | 100.0% \n",
      "train_loss: 0.33190, train_accr: 0.981 | val_loss: 0.38273, val_accr: 0.929 | 07:20.016 elapsed\n",
      "Epoch 052 |###################################################################### | 100.0% \n",
      "train_loss: 0.32978, train_accr: 0.983 | val_loss: 0.37162, val_accr: 0.940 | 05:36.261 elapsed\n",
      "Epoch 053 |###################################################################### | 100.0% \n",
      "train_loss: 0.33066, train_accr: 0.982 | val_loss: 0.37060, val_accr: 0.941 | 05:38.276 elapsed\n",
      "Epoch 054 |###################################################################### | 100.0% \n",
      "train_loss: 0.32974, train_accr: 0.983 | val_loss: 0.37315, val_accr: 0.939 | 05:35.998 elapsed\n",
      "Epoch 055 |###################################################################### | 100.0% \n",
      "train_loss: 0.32968, train_accr: 0.983 | val_loss: 0.37332, val_accr: 0.939 | 05:38.174 elapsed\n",
      "Epoch 056 |###################################################################### | 100.0% \n",
      "train_loss: 0.32913, train_accr: 0.984 | val_loss: 0.38068, val_accr: 0.931 | 05:36.567 elapsed\n",
      "Epoch 057 |###################################################################### | 100.0% \n",
      "train_loss: 0.33004, train_accr: 0.983 | val_loss: 0.36956, val_accr: 0.943 | 05:38.618 elapsed\n",
      "Epoch 058 |###################################################################### | 100.0% \n",
      "train_loss: 0.32831, train_accr: 0.985 | val_loss: 0.37476, val_accr: 0.936 | 05:34.625 elapsed\n",
      "Epoch 059 |###################################################################### | 100.0% \n",
      "train_loss: 0.32803, train_accr: 0.985 | val_loss: 0.37254, val_accr: 0.940 | 05:38.583 elapsed\n",
      "Epoch 060 |###################################################################### | 100.0% \n",
      "train_loss: 0.33166, train_accr: 0.981 | val_loss: 0.37313, val_accr: 0.939 | 05:36.540 elapsed\n",
      "Epoch 061 |###################################################################### | 100.0% \n",
      "train_loss: 0.32674, train_accr: 0.986 | val_loss: 0.37073, val_accr: 0.942 | 05:37.874 elapsed\n",
      "Epoch 062 |###################################################################### | 100.0% \n",
      "train_loss: 0.32820, train_accr: 0.985 | val_loss: 0.40118, val_accr: 0.910 | 05:36.873 elapsed\n",
      "Epoch 063 |###################################################################### | 100.0% \n",
      "train_loss: 0.32824, train_accr: 0.985 | val_loss: 0.37214, val_accr: 0.940 | 05:38.192 elapsed\n",
      "Epoch 064 |###################################################################### | 100.0% \n",
      "train_loss: 0.32854, train_accr: 0.985 | val_loss: 0.36260, val_accr: 0.949 | 05:36.106 elapsed\n",
      "Epoch 065 |###################################################################### | 100.0% \n",
      "train_loss: 0.32840, train_accr: 0.985 | val_loss: 0.36736, val_accr: 0.946 | 05:39.372 elapsed\n",
      "Epoch 066 |###################################################################### | 100.0% \n",
      "train_loss: 0.32776, train_accr: 0.985 | val_loss: 0.37417, val_accr: 0.939 | 05:36.209 elapsed\n",
      "Epoch 067 |###################################################################### | 100.0% \n",
      "train_loss: 0.32930, train_accr: 0.984 | val_loss: 0.36916, val_accr: 0.943 | 05:36.562 elapsed\n",
      "Epoch 068 |###################################################################### | 100.0% \n",
      "train_loss: 0.32748, train_accr: 0.986 | val_loss: 0.37726, val_accr: 0.935 | 05:35.924 elapsed\n",
      "Epoch 069 |###################################################################### | 100.0% \n",
      "train_loss: 0.32790, train_accr: 0.985 | val_loss: 0.37238, val_accr: 0.941 | 05:36.657 elapsed\n",
      "Epoch 070 |###################################################################### | 100.0% \n",
      "train_loss: 0.32862, train_accr: 0.984 | val_loss: 0.36971, val_accr: 0.943 | 05:38.445 elapsed\n",
      "Epoch 071 |###################################################################### | 100.0% \n",
      "train_loss: 0.32850, train_accr: 0.985 | val_loss: 0.38122, val_accr: 0.931 | 05:37.420 elapsed\n",
      "Epoch 072 |###################################################################### | 100.0% \n",
      "train_loss: 0.32716, train_accr: 0.986 | val_loss: 0.36614, val_accr: 0.946 | 05:37.753 elapsed\n",
      "Epoch 073 |###################################################################### | 100.0% \n",
      "train_loss: 0.32763, train_accr: 0.986 | val_loss: 0.36582, val_accr: 0.946 | 05:36.036 elapsed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 074 |###################################################################### | 100.0% \n",
      "train_loss: 0.32832, train_accr: 0.985 | val_loss: 0.37013, val_accr: 0.943 | 05:37.156 elapsed\n",
      "Epoch 075 |###################################################################### | 100.0% \n",
      "train_loss: 0.32628, train_accr: 0.987 | val_loss: 0.36981, val_accr: 0.942 | 05:39.509 elapsed\n",
      "Epoch 076 |###################################################################### | 100.0% \n",
      "train_loss: 0.32640, train_accr: 0.987 | val_loss: 0.36789, val_accr: 0.946 | 05:35.581 elapsed\n",
      "Epoch 077 |###################################################################### | 100.0% \n",
      "train_loss: 0.32741, train_accr: 0.986 | val_loss: 0.37562, val_accr: 0.937 | 05:39.208 elapsed\n",
      "Epoch 078 |###################################################################### | 100.0% \n",
      "train_loss: 0.32572, train_accr: 0.987 | val_loss: 0.37829, val_accr: 0.933 | 05:34.059 elapsed\n",
      "Epoch 079 |###################################################################### | 100.0% \n",
      "train_loss: 0.32882, train_accr: 0.984 | val_loss: 0.37277, val_accr: 0.939 | 05:37.859 elapsed\n",
      "Epoch 080 |###################################################################### | 100.0% \n",
      "train_loss: 0.32595, train_accr: 0.987 | val_loss: 0.37269, val_accr: 0.940 | 05:36.813 elapsed\n",
      "Epoch 081 |###################################################################### | 100.0% \n",
      "train_loss: 0.32721, train_accr: 0.986 | val_loss: 0.37457, val_accr: 0.938 | 05:37.574 elapsed\n",
      "Epoch 082 |###################################################################### | 100.0% \n",
      "train_loss: 0.32688, train_accr: 0.986 | val_loss: 0.37122, val_accr: 0.940 | 05:36.909 elapsed\n",
      "Epoch 083 |###################################################################### | 100.0% \n",
      "train_loss: 0.32743, train_accr: 0.986 | val_loss: 0.36821, val_accr: 0.944 | 05:37.941 elapsed\n",
      "Epoch 084 |###################################################################### | 100.0% \n",
      "train_loss: 0.32591, train_accr: 0.987 | val_loss: 0.37247, val_accr: 0.939 | 05:39.020 elapsed\n",
      "Epoch 085 |###################################################################### | 100.0% \n",
      "train_loss: 0.32472, train_accr: 0.988 | val_loss: 0.36782, val_accr: 0.945 | 05:35.038 elapsed\n",
      "Epoch 086 |###################################################################### | 100.0% \n",
      "train_loss: 0.32591, train_accr: 0.987 | val_loss: 0.37134, val_accr: 0.941 | 05:38.218 elapsed\n",
      "Epoch 087 |###################################################################### | 100.0% \n",
      "train_loss: 0.32530, train_accr: 0.988 | val_loss: 0.38229, val_accr: 0.930 | 05:37.340 elapsed\n",
      "Epoch 088 |###################################################################### | 100.0% \n",
      "train_loss: 0.32603, train_accr: 0.987 | val_loss: 0.36865, val_accr: 0.943 | 05:37.689 elapsed\n",
      "Epoch 089 |###################################################################### | 100.0% \n",
      "train_loss: 0.32486, train_accr: 0.988 | val_loss: 0.36765, val_accr: 0.945 | 05:36.473 elapsed\n",
      "Epoch 090 |###################################################################### | 100.0% \n",
      "train_loss: 0.32545, train_accr: 0.988 | val_loss: 0.36640, val_accr: 0.947 | 05:38.084 elapsed\n",
      "Epoch 091 |###################################################################### | 100.0% \n",
      "train_loss: 0.32555, train_accr: 0.988 | val_loss: 0.37506, val_accr: 0.938 | 05:36.658 elapsed\n",
      "Epoch 092 |###################################################################### | 100.0% \n",
      "train_loss: 0.32538, train_accr: 0.988 | val_loss: 0.36769, val_accr: 0.945 | 05:39.162 elapsed\n",
      "Epoch 093 |###################################################################### | 100.0% \n",
      "train_loss: 0.32333, train_accr: 0.990 | val_loss: 0.36930, val_accr: 0.943 | 05:36.586 elapsed\n",
      "Epoch 094 |###################################################################### | 100.0% \n",
      "train_loss: 0.32615, train_accr: 0.987 | val_loss: 0.38016, val_accr: 0.933 | 05:37.096 elapsed\n",
      "Epoch 095 |###################################################################### | 100.0% \n",
      "train_loss: 0.32441, train_accr: 0.989 | val_loss: 0.36936, val_accr: 0.943 | 05:35.646 elapsed\n",
      "Epoch 096 |###################################################################### | 100.0% \n",
      "train_loss: 0.32603, train_accr: 0.987 | val_loss: 0.37261, val_accr: 0.939 | 05:37.287 elapsed\n",
      "Epoch 097 |###################################################################### | 100.0% \n",
      "train_loss: 0.32418, train_accr: 0.989 | val_loss: 0.37385, val_accr: 0.938 | 05:35.991 elapsed\n",
      "Epoch 098 |###################################################################### | 100.0% \n",
      "train_loss: 0.32583, train_accr: 0.987 | val_loss: 0.37545, val_accr: 0.938 | 05:37.925 elapsed\n",
      "Epoch 099 |###################################################################### | 100.0% \n",
      "train_loss: 0.32632, train_accr: 0.987 | val_loss: 0.37167, val_accr: 0.941 | 05:35.421 elapsed\n",
      "Epoch 100 |###################################################################### | 100.0% \n",
      "train_loss: 0.32477, train_accr: 0.988 | val_loss: 0.37473, val_accr: 0.938 | 05:38.546 elapsed\n",
      "Best Model: B_--b_re_0.0001_16_2010302140_030_t_accr_0.9719_t_loss_0.341142_v_accr_0.9499_v_loss_0.362962.pt\n"
     ]
    }
   ],
   "source": [
    "phase_a = [[0, 0, 1]]\n",
    "phase_a_label = ['--b']\n",
    "\n",
    "for frb, name in zip(phase_a, phase_a_label):\n",
    "\n",
    "    train_aug_paths, valid_Xs = train_data_load('data_config_np-hd_frb_sv.pkl', frb, False)\n",
    "\n",
    "    LRs = [0.0001]\n",
    "    BSs = [16]\n",
    "    \n",
    "    Params = list(product(*[LRs, BSs]))\n",
    "\n",
    "    model_spec = 1\n",
    "\n",
    "    for i, (lr, bs) in enumerate(Params):\n",
    "\n",
    "        print('Learning Rate: {}, Batch Size: {}\\n'.format(lr, bs))  \n",
    "\n",
    "        ct = cnn_training(input_shape = [3, 512, 512], lr = lr, n_batch = bs, n_epoch = 100)\n",
    "\n",
    "        ct.run(train_aug_paths, valid_Xs, sampling_mode = None, batch_mode = 'equal', \n",
    "               network = 'CNN_v1', model_spec = model_spec, verbose = 1, \n",
    "               save_path = './model/', model_name = 'B_{}_re'.format(name), gpu_idx = 3,\n",
    "               classifier_file = None)  \n",
    "\n",
    "        if i != 0: model_spec = 0"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
